#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
================================================================================
DISTRIBUTED JOINS - Optimization Techniques for Production Scale
================================================================================

MODULE OVERVIEW:
----------------
Joins are one of the most expensive operations in distributed computing because
they typically require shuffling large amounts of data across the network. A
naive join can shuffle terabytes of data, causing jobs to run for hours instead
of minutes. Understanding join optimization is critical for production performance.

This module provides a comprehensive guide to:
1. How distributed joins work under the hood
2. Join strategies (Broadcast, Sort-Merge, Shuffle Hash)
3. Optimization techniques to minimize shuffle
4. Handling data skew in joins
5. Different join types and their performance
6. Production best practices

PURPOSE:
--------
Learn to:
â€¢ Choose the right join strategy for your data
â€¢ Minimize network shuffle with broadcast joins
â€¢ Partition data correctly for efficient joins
â€¢ Handle data skew that causes join bottlenecks
â€¢ Understand join execution in Spark UI
â€¢ Optimize multi-table joins

DISTRIBUTED JOIN FUNDAMENTALS:
------------------------------

Problem: Data on Different Nodes
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BEFORE JOIN                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Table A (Large - 100GB)           Table B (Large - 50GB)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Node 1: A1 (25GB)    â”‚          â”‚ Node 1: B1 (12GB)â”‚         â”‚
â”‚  â”‚ Node 2: A2 (25GB)    â”‚          â”‚ Node 2: B2 (13GB)â”‚         â”‚
â”‚  â”‚ Node 3: A3 (25GB)    â”‚          â”‚ Node 3: B3 (12GB)â”‚         â”‚
â”‚  â”‚ Node 4: A4 (25GB)    â”‚          â”‚ Node 4: B4 (13GB)â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                 â”‚
â”‚  Problem: Records with same join key on different nodes!       â”‚
â”‚  Solution: Shuffle data so matching keys are on same node      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

JOIN EXECUTION STRATEGIES:
--------------------------

Strategy 1: Broadcast Hash Join (Small Table)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BROADCAST JOIN (Optimal for small dimension tables)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Small Table B (100MB) â†’  Broadcast to ALL nodes               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚          Broadcast (B copied to all executors)          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚  Bâ”‚  Bâ”‚  Bâ”‚  Bâ”‚  Bâ”‚  Bâ”‚  Bâ”‚  Bâ”‚  Bâ”‚  Bâ”‚  Bâ”‚  Bâ”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â†“    â†“    â†“    â†“    â†“    â†“    â†“    â†“                â”‚
â”‚  Large Table A (100GB) stays partitioned:                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ A1 â”‚ A2 â”‚ A3 â”‚ A4 â”‚ A5 â”‚ A6 â”‚ A7 â”‚ A8 â”‚ A9 â”‚A10 â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜         â”‚
â”‚   Join locally on each executor (no shuffle for A!)           â”‚
â”‚                                                                â”‚
â”‚  âœ… Pros: No shuffle of large table, very fast                â”‚
â”‚  âŒ Cons: Small table must fit in executor memory             â”‚
â”‚  ğŸ“ Threshold: spark.sql.autoBroadcastJoinThreshold (10MB)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Strategy 2: Sort-Merge Join (Large-Large)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SORT-MERGE JOIN (Default for large-large joins)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Shuffle both tables by join key (hash partitioning)        â”‚
â”‚                                                                 â”‚
â”‚  Table A (before shuffle):        Table B (before shuffle):    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ A1  â”‚ A2  â”‚ A3  â”‚ A4  â”‚       â”‚ B1  â”‚ B2  â”‚ B3  â”‚          â”‚
â”‚  â”‚mixedâ”‚mixedâ”‚mixedâ”‚mixedâ”‚       â”‚mixedâ”‚mixedâ”‚mixedâ”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â†“                                â†“                      â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•           â”‚
â”‚         SHUFFLE BY KEY (Expensive!)                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•           â”‚
â”‚         â†“                                â†“                      â”‚
â”‚  Table A (after shuffle):         Table B (after shuffle):     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚key=1â”‚key=2â”‚key=3â”‚key=4â”‚       â”‚key=1â”‚key=2â”‚key=3â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                 â”‚
â”‚  2. Sort each partition by join key                            â”‚
â”‚  3. Merge sorted partitions (efficient)                        â”‚
â”‚                                                                 â”‚
â”‚  âœ… Pros: Works for large-large joins, scalable                â”‚
â”‚  âŒ Cons: Expensive shuffle, memory for sorting                â”‚
â”‚  ğŸ“Š Use: Default for DataFrames, most common                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Strategy 3: Shuffle Hash Join
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SHUFFLE HASH JOIN (Less common)                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Shuffle both tables by join key                            â”‚
â”‚  2. Build hash table for smaller side (per partition)          â”‚
â”‚  3. Probe with larger side                                     â”‚
â”‚                                                                 â”‚
â”‚  âœ… Pros: No sorting needed                                    â”‚
â”‚  âŒ Cons: Hash table must fit in memory, shuffle both sides    â”‚
â”‚  ğŸ“Š Use: spark.sql.join.preferSortMergeJoin=false              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

JOIN TYPES AND PERFORMANCE:
---------------------------

Join Type Comparison:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Join Type      â”‚ Result              â”‚ Shuffle      â”‚ Use Case      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INNER          â”‚ Only matching rows  â”‚ Both sides   â”‚ Standard join â”‚
â”‚ LEFT OUTER     â”‚ All left + matched  â”‚ Both sides   â”‚ Keep all left â”‚
â”‚ RIGHT OUTER    â”‚ All right + matched â”‚ Both sides   â”‚ Keep all rightâ”‚
â”‚ FULL OUTER     â”‚ All from both       â”‚ Both sides   â”‚ Union-like    â”‚
â”‚ LEFT SEMI      â”‚ Left rows that matchâ”‚ Both sides   â”‚ Filtering     â”‚
â”‚ LEFT ANTI      â”‚ Left rows no match  â”‚ Both sides   â”‚ Exclusion     â”‚
â”‚ CROSS          â”‚ Cartesian product   â”‚ Huge shuffle â”‚ Rare (avoid!) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Detailed Join Type Behavior:

INNER JOIN:
  A: [1, 2, 3]          B: [2, 3, 4]
  Result: [2, 3]  (only matching keys)

LEFT OUTER JOIN:
  A: [1, 2, 3]          B: [2, 3, 4]
  Result: [1, 2, 3]  (all from A, nulls for 1)

FULL OUTER JOIN:
  A: [1, 2, 3]          B: [2, 3, 4]
  Result: [1, 2, 3, 4]  (all from both, nulls for non-matches)

LEFT SEMI JOIN (Efficient Filtering):
  A: [1, 2, 3]          B: [2, 3, 4]
  Result: [2, 3]  (same as INNER but only A columns, no duplicates)
  
  Equivalent SQL: SELECT * FROM A WHERE A.key IN (SELECT key FROM B)
  âœ… Better than: INNER + SELECT DISTINCT + DROP B columns

LEFT ANTI JOIN (Exclusion):
  A: [1, 2, 3]          B: [2, 3, 4]
  Result: [1]  (only A rows with no match in B)
  
  Equivalent SQL: SELECT * FROM A WHERE A.key NOT IN (SELECT key FROM B)

OPTIMIZATION TECHNIQUES:
------------------------

Optimization 1: Broadcast Join for Small Tables
Rule: If one table < 10MB, ALWAYS broadcast

âŒ Bad (shuffle both):
orders.join(products, "product_id")  # Both tables shuffled

âœ… Good (broadcast small):
from pyspark.sql.functions import broadcast
orders.join(broadcast(products), "product_id")  # Only orders shuffled

Performance: 5-10x faster for large-small joins

Optimization 2: Pre-partition on Join Key
Rule: Partition both tables on join key BEFORE multiple joins

âŒ Bad (random partitions):
df1.join(df2, "key")  # Random partitions, full shuffle

âœ… Good (aligned partitions):
df1_partitioned = df1.repartition(100, "key")
df2_partitioned = df2.repartition(100, "key")
df1_partitioned.join(df2_partitioned, "key")  # Co-located data, minimal shuffle

Optimization 3: Cache After Partitioning
Rule: If joining same table multiple times, cache after partitioning

âœ… Best:
df_partitioned = df.repartition(100, "key").cache()
df_partitioned.count()  # Materialize cache
result1 = df_partitioned.join(other1, "key")
result2 = df_partitioned.join(other2, "key")  # Uses cached partitions

Optimization 4: Filter BEFORE Join
Rule: Reduce data size before expensive operations

âŒ Bad (join then filter):
df1.join(df2, "key").filter(col("amount") > 1000)  # Full shuffle, then filter

âœ… Good (filter then join):
df1_filtered = df1.filter(col("amount") > 1000)
df1_filtered.join(df2, "key")  # Less data to shuffle

Optimization 5: Use Appropriate Join Type
Rule: Use LEFT SEMI for existence checks

âŒ Bad (inefficient):
df1.join(df2, "key", "inner") \\
   .select(df1.columns) \\
   .distinct()  # Shuffle, duplicate elimination

âœ… Good (efficient):
df1.join(df2, "key", "left_semi")  # No duplicates, only df1 columns

DATA SKEW IN JOINS:
-------------------

Problem: Skewed Join Keys
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              UNBALANCED JOIN (Data Skew)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Partition distribution after shuffle by join key:             â”‚
â”‚  â”Œâ”€â”¬â”€â”¬â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”¬â”€â”    â”‚
â”‚  â”‚Pâ”‚Pâ”‚Pâ”‚      Partition 3 (90% of data)              â”‚Pâ”‚Pâ”‚    â”‚
â”‚  â”‚0â”‚1â”‚2â”‚      One executor overloaded                â”‚4â”‚5â”‚    â”‚
â”‚  â””â”€â”´â”€â”´â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”´â”€â”˜    â”‚
â”‚   2m 2m 2m          1 hour (bottleneck!)            2m 2m      â”‚
â”‚                                                                 â”‚
â”‚  Cause: One key (e.g., user_id="popular") has 90% of data      â”‚
â”‚  Effect: Job takes 1 hour instead of 2 minutes                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Skew Mitigation Technique 1: Salting
For skewed fact table joining dimension table:

# Step 1: Add salt to fact table (split hot keys)
from pyspark.sql.functions import concat, lit, rand
fact_salted = fact.withColumn("salt", (rand() * 10).cast("int")) \\
    .withColumn("salted_key", concat(col("user_id"), lit("_"), col("salt")))

# Step 2: Replicate dimension table with all salts
from pyspark.sql.functions import explode, array
dim_replicated = dim.withColumn("salt", explode(array([lit(i) for i in range(10)]))) \\
    .withColumn("salted_key", concat(col("user_id"), lit("_"), col("salt")))

# Step 3: Join on salted key (distributed across 10 partitions per key)
result = fact_salted.join(dim_replicated, "salted_key")

Skew Mitigation Technique 2: Separate Hot Keys
# Step 1: Identify hot keys
hot_keys = fact.groupBy("user_id").count() \\
    .filter(col("count") > 100000) \\
    .select("user_id")

# Step 2: Split into hot and cold
fact_hot = fact.join(broadcast(hot_keys), "user_id", "left_semi")
fact_cold = fact.join(broadcast(hot_keys), "user_id", "left_anti")

# Step 3: Process separately
result_hot = fact_hot.join(broadcast(dim), "user_id")  # Broadcast for hot
result_cold = fact_cold.join(dim, "user_id")  # Regular join for cold
result = result_hot.union(result_cold)

Skew Mitigation Technique 3: Adaptive Query Execution (Spark 3+)
spark.conf.set("spark.sql.adaptive.enabled", "true")
spark.conf.set("spark.sql.adaptive.skewJoin.enabled", "true")
spark.conf.set("spark.sql.adaptive.skewJoin.skewedPartitionFactor", "5")
spark.conf.set("spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes", "256MB")

# Spark automatically detects and handles skew

MULTI-TABLE JOINS:
------------------

Optimization: Join Order Matters
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âŒ BAD ORDER (Large â†’ Medium â†’ Small):                         â”‚
â”‚                                                                 â”‚
â”‚  large_df (100GB)                                               â”‚
â”‚      .join(medium_df (10GB), "key1")  â† Shuffle 100GB + 10GB   â”‚
â”‚      .join(small_df (100MB), "key2")  â† Shuffle 110GB + 100MB  â”‚
â”‚                                                                 â”‚
â”‚  Total shuffle: ~220GB                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ… GOOD ORDER (Small â†’ Medium â†’ Large):                        â”‚
â”‚                                                                 â”‚
â”‚  small_df (100MB)                                               â”‚
â”‚      .join(medium_df (10GB), "key1")  â† Broadcast 100MB        â”‚
â”‚      .join(large_df (100GB), "key2")  â† Shuffle 10GB + 100GB   â”‚
â”‚                                                                 â”‚
â”‚  Total shuffle: ~110GB (2x improvement!)                        â”‚
â”‚                                                                 â”‚
â”‚  Rule: Join smallest tables first, largest last                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Star Schema Joins (Fact + Multiple Dimensions):
# Broadcast all small dimension tables
fact.join(broadcast(dim1), "dim1_id") \\
    .join(broadcast(dim2), "dim2_id") \\
    .join(broadcast(dim3), "dim3_id")

# Only fact table shuffled once

PERFORMANCE BENCHMARKS:
-----------------------

Typical Performance Impact:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scenario                 â”‚ Naive        â”‚ Optimized    â”‚ Speedup   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Large-Small Join         â”‚ 45 min       â”‚ 5 min        â”‚ 9x        â”‚
â”‚ (with broadcast)         â”‚              â”‚              â”‚           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Large-Large Join         â”‚ 30 min       â”‚ 10 min       â”‚ 3x        â”‚
â”‚ (with pre-partition)     â”‚              â”‚              â”‚           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Skewed Join              â”‚ 2 hours      â”‚ 20 min       â”‚ 6x        â”‚
â”‚ (with salting)           â”‚              â”‚              â”‚           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Multi-table Join         â”‚ 1 hour       â”‚ 15 min       â”‚ 4x        â”‚
â”‚ (join order + broadcast) â”‚              â”‚              â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MONITORING & DEBUGGING:
-----------------------

Spark UI Metrics to Check:
1. SQL Tab â†’ Query Plan:
   â€¢ Look for "Exchange" (shuffle operations)
   â€¢ BroadcastHashJoin vs SortMergeJoin
   â€¢ Shuffle read/write sizes

2. Stages Tab â†’ Task Metrics:
   â€¢ Shuffle Read Size: Look for skew (max >> median)
   â€¢ Task Duration: Identify stragglers
   â€¢ GC Time: Should be < 10% of task time

3. Executors Tab:
   â€¢ Memory usage during join
   â€¢ Shuffle read/write per executor

SQL Plan Example:
== Physical Plan ==
*(5) Project [...]
+- *(5) SortMergeJoin [id#1], [id#2]  â† Join type
   :- *(2) Sort [id#1]
   :  +- Exchange hashpartitioning(id#1, 200)  â† Shuffle!
   :     +- *(1) Filter [...]
   +- *(4) Sort [id#2]
      +- Exchange hashpartitioning(id#2, 200)  â† Shuffle!
         +- *(3) Filter [...]

BEST PRACTICES CHECKLIST:
-------------------------

â˜ Use broadcast() for tables < 10MB
â˜ Filter data before joins
â˜ Partition both tables on join key (same partition count)
â˜ Cache if joining same table multiple times
â˜ Use left_semi for existence checks
â˜ Avoid full outer joins when possible
â˜ Join smallest tables first in multi-joins
â˜ Monitor shuffle size in Spark UI
â˜ Enable Adaptive Query Execution (Spark 3+)
â˜ Handle data skew (salting or separate processing)
â˜ Use appropriate join type (don't default to inner)
â˜ Avoid cross joins (cartesian products)

COMMON MISTAKES:
----------------

âŒ #1: Not broadcasting small tables
âŒ #2: Different partition counts on join tables
âŒ #3: Joining without filtering first
âŒ #4: Ignoring data skew
âŒ #5: Using inner join + distinct instead of left_semi
âŒ #6: Wrong join order in multi-table joins
âŒ #7: Not caching repeatedly joined tables
âŒ #8: Using show() to inspect large join results (use explain())

TARGET AUDIENCE:
----------------
â€¢ Data engineers optimizing slow joins
â€¢ Anyone experiencing shuffle-related performance issues
â€¢ Teams handling multi-TB join operations
â€¢ Developers debugging OOM errors during joins

RELATED RESOURCES:
------------------
â€¢ cluster_computing/02_data_partitioning.py (partitioning strategies)
â€¢ cluster_computing/04_aggregations_at_scale.py
â€¢ security/02_common_mistakes.py (#8 Cartesian Joins, #9 Broadcast Joins)
â€¢ Spark SQL Performance Tuning: https://spark.apache.org/docs/latest/sql-performance-tuning.html

AUTHOR: PySpark Education Project
LICENSE: Educational Use - MIT License
VERSION: 2.0.0 - Comprehensive Distributed Joins Guide
UPDATED: 2024
================================================================================
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import broadcast, col, count, lit
import time


def create_spark():
    return SparkSession.builder \
        .appName("DistributedJoins") \
        .master("local[4]") \
        .config("spark.sql.shuffle.partitions", "4") \
        .config("spark.sql.autoBroadcastJoinThreshold", "10485760")  # 10MB \
        .getOrCreate()


def demonstrate_naive_join(spark):
    """Show the problem with naive joins."""
    print("=" * 70)
    print("1. NAIVE JOIN (Unoptimized)")
    print("=" * 70)
    
    # Create large datasets
    orders = spark.range(1, 100001).toDF("order_id") \
        .withColumn("customer_id", (col("order_id") % 1000).cast("int")) \
        .withColumn("amount", (col("order_id") * 10).cast("int"))
    
    customers = spark.range(1, 1001).toDF("customer_id") \
        .withColumn("name", lit("Customer"))
    
    print(f"ğŸ“Š Orders: {orders.count():,} rows")
    print(f"ğŸ“Š Customers: {customers.count():,} rows")
    
    # Naive join
    print("\nâš ï¸  Naive join (no optimization):")
    start = time.time()
    result = orders.join(customers, "customer_id")
    result.write.mode("overwrite").format("noop").save()
    naive_time = time.time() - start
    
    print(f"   Rows: {result.count():,}")
    print(f"   Time: {naive_time:.3f}s")
    print(f"   âš ï¸  Full shuffle: Both tables shuffled across network")
    
    return naive_time


def demonstrate_broadcast_join(spark):
    """Optimize with broadcast join for small tables."""
    print("\n" + "=" * 70)
    print("2. BROADCAST JOIN (Optimized for Small Tables)")
    print("=" * 70)
    
    # Same datasets
    orders = spark.range(1, 100001).toDF("order_id") \
        .withColumn("customer_id", (col("order_id") % 1000).cast("int")) \
        .withColumn("amount", (col("order_id") * 10).cast("int"))
    
    customers = spark.range(1, 1001).toDF("customer_id") \
        .withColumn("name", lit("Customer"))
    
    # Broadcast join
    print("\nâœ… Broadcast join (small table sent to all nodes):")
    start = time.time()
    result = orders.join(broadcast(customers), "customer_id")
    result.write.mode("overwrite").format("noop").save()
    broadcast_time = time.time() - start
    
    print(f"   Rows: {result.count():,}")
    print(f"   Time: {broadcast_time:.3f}s")
    print(f"   âœ… No shuffle: Customers broadcast to all executors")
    print(f"   âœ… Only orders partitioned")
    
    print("\nğŸ’¡ When to use broadcast join:")
    print("   - Small table < 10MB (default threshold)")
    print("   - Small table fits in executor memory")
    print("   - Avoid shuffle for large table")
    
    return broadcast_time


def demonstrate_partition_join(spark):
    """Optimize with pre-partitioning on join key."""
    print("\n" + "=" * 70)
    print("3. PARTITIONED JOIN (Optimized for Large Tables)")
    print("=" * 70)
    
    # Larger datasets where broadcast won't work
    orders = spark.range(1, 500001).toDF("order_id") \
        .withColumn("customer_id", (col("order_id") % 5000).cast("int")) \
        .withColumn("amount", (col("order_id") * 10).cast("int"))
    
    customers = spark.range(1, 5001).toDF("customer_id") \
        .withColumn("name", lit("Customer")) \
        .withColumn("city", lit("City"))
    
    print(f"ğŸ“Š Orders: {orders.count():,} rows")
    print(f"ğŸ“Š Customers: {customers.count():,} rows")
    print("   (Too large for broadcast)")
    
    # Without pre-partitioning
    print("\nâŒ Without pre-partitioning:")
    start = time.time()
    result_bad = orders.join(customers, "customer_id")
    result_bad.write.mode("overwrite").format("noop").save()
    bad_time = time.time() - start
    print(f"   Time: {bad_time:.3f}s")
    
    # With pre-partitioning
    print("\nâœ… With pre-partitioning on join key:")
    start = time.time()
    orders_partitioned = orders.repartition(8, "customer_id")
    customers_partitioned = customers.repartition(8, "customer_id")
    result_good = orders_partitioned.join(customers_partitioned, "customer_id")
    result_good.write.mode("overwrite").format("noop").save()
    good_time = time.time() - start
    
    print(f"   Time: {good_time:.3f}s")
    print(f"   Speedup: {bad_time / good_time:.2f}x")
    print(f"   âœ… Co-located: Same keys on same nodes")
    print(f"   âœ… Reduced shuffle: Data already partitioned correctly")


def demonstrate_join_types(spark):
    """Compare different join types and their shuffle behavior."""
    print("\n" + "=" * 70)
    print("4. JOIN TYPES & SHUFFLE BEHAVIOR")
    print("=" * 70)
    
    # Create datasets
    df1 = spark.range(1, 10001).toDF("id") \
        .withColumn("value1", col("id") * 10)
    
    df2 = spark.range(5000, 15001).toDF("id") \
        .withColumn("value2", col("id") * 20)
    
    print(f"ğŸ“Š DataFrame 1: {df1.count():,} rows (1-10,000)")
    print(f"ğŸ“Š DataFrame 2: {df2.count():,} rows (5,000-15,000)")
    print(f"   Overlap: 5,000 rows (5,000-10,000)")
    
    # Inner join
    print("\nğŸ”— INNER JOIN:")
    inner_result = df1.join(df2, "id", "inner")
    inner_count = inner_result.count()
    print(f"   Result: {inner_count:,} rows (only overlapping)")
    print(f"   Shuffle: Both sides")
    
    # Left outer join
    print("\nğŸ”— LEFT OUTER JOIN:")
    left_result = df1.join(df2, "id", "left")
    left_count = left_result.count()
    print(f"   Result: {left_count:,} rows (all from left)")
    print(f"   Shuffle: Both sides")
    
    # Right outer join
    print("\nğŸ”— RIGHT OUTER JOIN:")
    right_result = df1.join(df2, "id", "right")
    right_count = right_result.count()
    print(f"   Result: {right_count:,} rows (all from right)")
    print(f"   Shuffle: Both sides")
    
    # Full outer join
    print("\nğŸ”— FULL OUTER JOIN:")
    full_result = df1.join(df2, "id", "full")
    full_count = full_result.count()
    print(f"   Result: {full_count:,} rows (all from both)")
    print(f"   Shuffle: Both sides (most expensive)")
    
    # Left semi join (filtering)
    print("\nğŸ”— LEFT SEMI JOIN:")
    semi_result = df1.join(df2, "id", "left_semi")
    semi_count = semi_result.count()
    print(f"   Result: {semi_count:,} rows (left rows that match)")
    print(f"   Columns: Only from left table")
    print(f"   Use case: Filtering without duplicating data")


def demonstrate_skewed_join(spark):
    """Handle data skew in joins."""
    print("\n" + "=" * 70)
    print("5. HANDLING SKEWED JOINS")
    print("=" * 70)
    
    # Create skewed dataset (90% have same key)
    skewed_data = []
    for i in range(1, 10001):
        if i < 9000:
            key = 1  # 90% of data
        else:
            key = i % 100
        skewed_data.append((i, key, i * 100))
    
    orders_skewed = spark.createDataFrame(skewed_data, ["order_id", "customer_id", "amount"])
    customers = spark.range(1, 101).toDF("customer_id") \
        .withColumn("name", lit("Customer"))
    
    print("ğŸ“Š Skewed dataset:")
    orders_skewed.groupBy("customer_id").count() \
        .orderBy(col("count").desc()).show(5)
    
    # Problem: Skewed join
    print("\nâŒ Problem: Skewed join (one partition overloaded):")
    start = time.time()
    result_skewed = orders_skewed.join(customers, "customer_id")
    result_skewed.write.mode("overwrite").format("noop").save()
    skewed_time = time.time() - start
    print(f"   Time: {skewed_time:.3f}s")
    print(f"   âš ï¸  One partition processes 90% of data")
    
    # Solution: Salting + broadcast
    print("\nâœ… Solution 1: Broadcast join (if customers small):")
    start = time.time()
    result_broadcast = orders_skewed.join(broadcast(customers), "customer_id")
    result_broadcast.write.mode("overwrite").format("noop").save()
    broadcast_time = time.time() - start
    print(f"   Time: {broadcast_time:.3f}s")
    print(f"   Speedup: {skewed_time / broadcast_time:.2f}x")
    print(f"   âœ… No shuffle, no skew issue")
    
    # Solution: Salting (for large dimension tables)
    print("\nâœ… Solution 2: Salting (if both tables large):")
    from pyspark.sql.functions import concat, rand, lit as spark_lit, explode, array
    
    # Add salt to fact table
    orders_salted = orders_skewed.withColumn(
        "salt",
        (rand() * 10).cast("int")
    ).withColumn(
        "salted_key",
        concat(col("customer_id").cast("string"), spark_lit("_"), col("salt").cast("string"))
    )
    
    # Explode dimension table with all salt values
    customers_exploded = customers.withColumn(
        "salt",
        explode(array([lit(i) for i in range(10)]))
    ).withColumn(
        "salted_key",
        concat(col("customer_id").cast("string"), spark_lit("_"), col("salt").cast("string"))
    )
    
    start = time.time()
    result_salted = orders_salted.join(customers_exploded, "salted_key")
    result_salted.write.mode("overwrite").format("noop").save()
    salted_time = time.time() - start
    
    print(f"   Time: {salted_time:.3f}s")
    print(f"   âœ… Distributed: Skewed key split across 10 partitions")
    print(f"   âœ… Balanced: Each partition processes ~10% of data")


def demonstrate_join_best_practices(spark):
    """Summary of join best practices."""
    print("\n" + "=" * 70)
    print("6. JOIN BEST PRACTICES")
    print("=" * 70)
    
    print("""
ğŸ“‹ Decision Tree for Joins:

â”Œâ”€ Small table (< 10MB)?
â”‚  â””â”€ YES â†’ Use broadcast join âœ…
â”‚     from pyspark.sql.functions import broadcast
â”‚     result = large.join(broadcast(small), "key")
â”‚
â””â”€ Both tables large?
   â”‚
   â”œâ”€ Same partition count & key?
   â”‚  â””â”€ YES â†’ Already optimized âœ…
   â”‚
   â””â”€ Different partitions?
      â””â”€ Repartition both on join key
         df1 = df1.repartition(N, "key")
         df2 = df2.repartition(N, "key")
         result = df1.join(df2, "key")

ğŸ¯ Optimization Checklist:

1. âœ… Filter before join (reduce data size)
2. âœ… Use broadcast for small tables (< 10MB)
3. âœ… Partition both tables on join key
4. âœ… Use same partition count for both tables
5. âœ… Cache tables if joining multiple times
6. âœ… Use left semi join for filtering
7. âœ… Handle skew with salting or broadcast
8. âœ… Monitor Spark UI for shuffle size

âš ï¸  Common Mistakes:

1. âŒ Joining without filtering first
2. âŒ Not broadcasting small tables
3. âŒ Different partition counts for join tables
4. âŒ Ignoring data skew
5. âŒ Using full outer join when not needed
6. âŒ Multiple joins without caching
    """)


def main():
    spark = create_spark()
    
    print("ğŸ”— DISTRIBUTED JOINS IN PYSPARK")
    print("=" * 70)
    
    # 1. Naive join
    naive_time = demonstrate_naive_join(spark)
    
    # 2. Broadcast join
    broadcast_time = demonstrate_broadcast_join(spark)
    
    # 3. Partitioned join
    demonstrate_partition_join(spark)
    
    # 4. Join types
    demonstrate_join_types(spark)
    
    # 5. Skewed joins
    demonstrate_skewed_join(spark)
    
    # 6. Best practices
    demonstrate_join_best_practices(spark)
    
    print("\n" + "=" * 70)
    print("âœ… DISTRIBUTED JOINS DEMO COMPLETE!")
    print("=" * 70)
    print("\nğŸ“ Key Takeaways:")
    print(f"   1. Broadcast join: {naive_time / broadcast_time:.2f}x faster for small tables")
    print("   2. Partition on join key for large-large joins")
    print("   3. Handle skew with salting or broadcast")
    print("   4. Filter before join to reduce shuffle")
    print("   5. Monitor Spark UI shuffle metrics")
    print("   6. Cache if joining same tables multiple times")
    
    spark.stop()


if __name__ == "__main__":
    main()
