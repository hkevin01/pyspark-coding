#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
================================================================================
DRIVER AND EXECUTOR RESPONSIBILITIES - Complete Demonstration
================================================================================

MODULE OVERVIEW:
----------------
This module provides a comprehensive demonstration of the Driver-Executor
architecture in Apache Spark. It shows the distinct responsibilities,
communication patterns, and resource allocation between the Driver program
and Executor processes that form the foundation of Spark's distributed
computing model.

Understanding the Driver-Executor relationship is CRITICAL for:
â€¢ Debugging performance issues
â€¢ Optimizing resource allocation
â€¢ Understanding failure modes
â€¢ Writing efficient Spark applications
â€¢ Troubleshooting memory problems

PURPOSE:
--------
Spark uses a master-worker architecture where:
â€¢ DRIVER = Master (plans and coordinates)
â€¢ EXECUTORS = Workers (execute and store data)

This module demonstrates:
1. What the Driver does (planning, scheduling, coordination)
2. What Executors do (task execution, data storage, computation)
3. How they communicate (task assignment, result collection, shuffles)
4. Failure handling (task retries, executor failures, lineage)
5. Resource allocation (memory, cores, parallelism)

TARGET AUDIENCE:
----------------
â€¢ Data engineers learning Spark architecture
â€¢ Developers debugging Spark applications
â€¢ System administrators configuring clusters
â€¢ Anyone experiencing memory or performance issues

================================================================================
DRIVER RESPONSIBILITIES (The "Brain"):
================================================================================

The Driver is the control center of your Spark application. It runs your
main() function and coordinates all work across the cluster.

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DRIVER PROCESS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  1. MAINTAINS SPARKSESSION                                      â”‚
â”‚     â€¢ Entry point for all Spark functionality                   â”‚
â”‚     â€¢ Holds configuration                                       â”‚
â”‚     â€¢ Manages SparkContext                                      â”‚
â”‚                                                                  â”‚
â”‚  2. BUILDS EXECUTION PLANS                                      â”‚
â”‚     â€¢ Parses user code into logical plan                        â”‚
â”‚     â€¢ Optimizes with Catalyst optimizer                         â”‚
â”‚     â€¢ Generates physical execution plan                         â”‚
â”‚     â€¢ Creates DAG (Directed Acyclic Graph)                      â”‚
â”‚                                                                  â”‚
â”‚  3. SCHEDULES JOBS/STAGES/TASKS                                 â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚     â”‚ ACTION (e.g., .count())                â”‚                 â”‚
â”‚     â”‚    â†“                                   â”‚                 â”‚
â”‚     â”‚ JOB (one per action)                   â”‚                 â”‚
â”‚     â”‚    â†“                                   â”‚                 â”‚
â”‚     â”‚ STAGES (split at shuffle boundaries)   â”‚                 â”‚
â”‚     â”‚    â†“                                   â”‚                 â”‚
â”‚     â”‚ TASKS (one per partition)              â”‚                 â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                  â”‚
â”‚  4. TRACKS EXECUTOR STATUS                                      â”‚
â”‚     â€¢ Which executors are available?                            â”‚
â”‚     â€¢ How much memory do they have?                             â”‚
â”‚     â€¢ Are they responding?                                      â”‚
â”‚                                                                  â”‚
â”‚  5. COLLECTS RESULTS                                            â”‚
â”‚     â€¢ Receives task completion notifications                    â”‚
â”‚     â€¢ Aggregates results from all executors                     â”‚
â”‚     â€¢ Returns final result to user                              â”‚
â”‚                                                                  â”‚
â”‚  6. MANAGES BROADCAST VARIABLES                                 â”‚
â”‚     â€¢ Efficiently distributes read-only data                    â”‚
â”‚     â€¢ Sends to all executors once                               â”‚
â”‚     â€¢ Avoids sending same data with every task                  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DRIVER MEMORY CONTAINS:
â€¢ SparkSession and SparkContext
â€¢ Execution plans (DAGs)
â€¢ Job/stage/task tracking metadata
â€¢ Broadcast variables
â€¢ Results from collect(), take(), etc. (âš ï¸ Can cause OOM!)

âš ï¸  DRIVER FAILURE = ENTIRE APPLICATION FAILS (single point of failure)

================================================================================
EXECUTOR RESPONSIBILITIES (The "Workers"):
================================================================================

Executors are worker processes that run on cluster nodes. They do the actual
data processing work.

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      EXECUTOR PROCESS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  1. EXECUTE TASKS ON DATA PARTITIONS                            â”‚
â”‚     â€¢ Receives serialized task code from driver                 â”‚
â”‚     â€¢ Runs task on local partition of data                      â”‚
â”‚     â€¢ Each task processes ONE partition                         â”‚
â”‚                                                                  â”‚
â”‚  2. STORE DATA PARTITIONS IN MEMORY/DISK                        â”‚
â”‚     â€¢ cache() / persist() stores data locally                   â”‚
â”‚     â€¢ Intermediate shuffle data                                 â”‚
â”‚     â€¢ Broadcast variable copies                                 â”‚
â”‚                                                                  â”‚
â”‚  3. PERFORM COMPUTATIONS                                        â”‚
â”‚     â€¢ Filter, map, flatMap, etc.                                â”‚
â”‚     â€¢ All transformations run on executors                      â”‚
â”‚     â€¢ Use executor cores for parallel execution                 â”‚
â”‚                                                                  â”‚
â”‚  4. HANDLE SHUFFLE OPERATIONS                                   â”‚
â”‚     â€¢ SHUFFLE WRITE: Group data and write to disk               â”‚
â”‚     â€¢ SHUFFLE READ: Read data from other executors              â”‚
â”‚     â€¢ Shuffle files survive executor failures                   â”‚
â”‚                                                                  â”‚
â”‚  5. REPORT METRICS TO DRIVER                                    â”‚
â”‚     â€¢ Task completion status                                    â”‚
â”‚     â€¢ Records processed                                         â”‚
â”‚     â€¢ Bytes read/written                                        â”‚
â”‚     â€¢ Execution time                                            â”‚
â”‚     â€¢ Memory usage                                              â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

EXECUTOR MEMORY CONTAINS:
â€¢ Data partitions (cached DataFrames/RDDs)
â€¢ Task execution memory (for joins, aggregations)
â€¢ Shuffle buffers (shuffle read/write)
â€¢ Broadcast variable copies

âš ï¸  EXECUTOR FAILURE = TASKS RECOMPUTED (fault tolerant via lineage)

================================================================================
DRIVER â†” EXECUTOR COMMUNICATION FLOW:
================================================================================

Step-by-step communication for a simple count() operation:

1. JOB SUBMISSION (Driver â†’ Executors):
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚          â”‚  "Execute Task 0: count ids"   â”‚          â”‚
   â”‚  DRIVER  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ Exec 1   â”‚
   â”‚          â”‚  "Execute Task 1: count ids"   â”‚          â”‚
   â”‚          â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ Exec 2   â”‚
   â”‚          â”‚  "Execute Task 2: count ids"   â”‚          â”‚
   â”‚          â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ Exec 3   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2. TASK EXECUTION (Executors work independently):
   Exec 1: Partition 0 â†’ count = 250
   Exec 2: Partition 1 â†’ count = 250
   Exec 3: Partition 2 â†’ count = 250

3. RESULT COLLECTION (Executors â†’ Driver):
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚          â”‚ <â”€â”€â”€â”€â”€ "Task 0 complete: 250" â”€â”‚ Exec 1   â”‚
   â”‚  DRIVER  â”‚ <â”€â”€â”€â”€â”€ "Task 1 complete: 250" â”€â”‚ Exec 2   â”‚
   â”‚          â”‚ <â”€â”€â”€â”€â”€ "Task 2 complete: 250" â”€â”‚ Exec 3   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

4. FINAL AGGREGATION (Driver):
   Driver sums: 250 + 250 + 250 = 750
   Returns 750 to user

SHUFFLE COMMUNICATION (Executor â†” Executor):
When doing groupBy, join, or aggregation:

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Exec 1   â”‚ <â”€â”€â”€â”€> â”‚ Exec 2   â”‚   Exchange data
   â”‚ (writes) â”‚         â”‚ (reads)  â”‚   across network
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†•                    â†•
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Exec 3   â”‚ <â”€â”€â”€â”€> â”‚ Exec 4   â”‚
   â”‚ (writes) â”‚         â”‚ (reads)  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Executors write shuffle files to local disk, then other executors
read those files over the network. This is called a "shuffle".

================================================================================
FAILURE HANDLING & FAULT TOLERANCE:
================================================================================

Spark provides fault tolerance through LINEAGE - the DAG of operations
that tracks how to recompute lost data.

SCENARIO 1: Task Failure
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Problem: Task fails due to temporary issue (network timeout, etc.)
Solution: Driver detects failure â†’ Reschedules task on same/different executor
Result: âœ… Transparent retry, user doesn't see failure

SCENARIO 2: Executor Failure
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Problem: Executor process crashes or becomes unresponsive
Solution:
  1. Driver marks executor as lost
  2. Driver requests new executor from cluster manager
  3. Driver reschedules all tasks from failed executor
  4. Uses lineage to recompute lost partitions
Result: âœ… Application continues, recomputes lost data

SCENARIO 3: Driver Failure
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Problem: Driver process crashes
Solution: âš ï¸  NO AUTOMATIC RECOVERY - entire application fails!
Why: Driver holds all state (execution plans, task tracking, etc.)
Mitigation:
  â€¢ Use --deploy-mode cluster (driver runs on cluster, not client)
  â€¢ Enable checkpointing for Structured Streaming
  â€¢ Use external orchestration (Kubernetes, Airflow) to restart

SCENARIO 4: Data Loss (Cached RDD)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Problem: Executor with cached partition crashes
Solution:
  1. Driver detects cache partition is lost
  2. Uses lineage to recompute partition from source
  3. Caches recomputed partition on available executor
Result: âœ… Cache rebuilt automatically

SHUFFLE PERSISTENCE:
When shuffle data is written to disk:
  â€¢ Shuffle files persist even if executor fails
  â€¢ External shuffle service keeps shuffle data available
  â€¢ Reduces recomputation after executor failures

================================================================================
RESOURCE ALLOCATION & CONFIGURATION:
================================================================================

TYPICAL CLUSTER SETUP:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLIENT MACHINE (where you run spark-submit)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  spark-submit --master yarn \\                       â”‚ â”‚
â”‚  â”‚    --deploy-mode cluster \\                          â”‚ â”‚
â”‚  â”‚    --driver-memory 4g \\                             â”‚ â”‚
â”‚  â”‚    --driver-cores 2 \\                               â”‚ â”‚
â”‚  â”‚    --executor-memory 8g \\                           â”‚ â”‚
â”‚  â”‚    --executor-cores 4 \\                             â”‚ â”‚
â”‚  â”‚    --num-executors 10 \\                             â”‚ â”‚
â”‚  â”‚    my_app.py                                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“ Submits to Cluster Manager
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLUSTER (YARN / Kubernetes / Standalone)                 â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚  â”‚   DRIVER     â”‚  Node 1                                 â”‚
â”‚  â”‚   4GB / 2c   â”‚  â€¢ Plans execution                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â€¢ Schedules tasks                      â”‚
â”‚                    â€¢ Collects results                      â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  EXECUTORS                                          â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚                                                     â”‚ â”‚
â”‚  â”‚  Node 2-11 (10 executor nodes):                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚ Executor 1 â”‚  â”‚ Executor 2 â”‚  â”‚    ...     â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  8GB / 4c  â”‚  â”‚  8GB / 4c  â”‚  â”‚ Executor 10â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â”‚                                                     â”‚ â”‚
â”‚  â”‚  Each executor:                                     â”‚ â”‚
â”‚  â”‚  â€¢ Runs 4 tasks concurrently (4 cores)             â”‚ â”‚
â”‚  â”‚  â€¢ Stores up to 8GB of cached data                 â”‚ â”‚
â”‚  â”‚  â€¢ Handles local shuffle read/write                â”‚ â”‚
â”‚  â”‚                                                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â”‚  TOTAL CLUSTER RESOURCES:                                 â”‚
â”‚  â€¢ Driver: 4GB memory, 2 cores                            â”‚
â”‚  â€¢ Executors: 10 Ã— 8GB = 80GB memory                      â”‚
â”‚  â€¢ Parallelism: 10 Ã— 4 = 40 concurrent tasks              â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

KEY CONFIGURATION PARAMETERS:

--driver-memory 4g
  â””â”€> Memory for driver process
      â€¢ Holds SparkSession, execution plans, broadcast vars
      â€¢ âš ï¸  collect() results come here (can cause OOM!)
      â€¢ Typical: 2-8GB

--driver-cores 2
  â””â”€> CPU cores for driver
      â€¢ Schedules tasks, collects results
      â€¢ Usually 1-4 cores sufficient

--executor-memory 8g
  â””â”€> Memory per executor
      â€¢ Caches data partitions
      â€¢ Task execution memory (joins, aggregations)
      â€¢ Shuffle buffers
      â€¢ Typical: 4-16GB per executor

--executor-cores 4
  â””â”€> CPU cores per executor
      â€¢ Each core runs 1 task at a time
      â€¢ More cores = more parallel tasks
      â€¢ Typical: 4-8 cores per executor

--num-executors 10
  â””â”€> Number of executor processes
      â€¢ More executors = more parallelism
      â€¢ Balance: too many = overhead, too few = underutilized

MEMORY BREAKDOWN (per Executor):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EXECUTOR MEMORY (8GB example)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Reserved Memory (300MB)      â”‚ 4%     â”‚  Spark overhead
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Storage Memory (3.85GB)      â”‚ 48%    â”‚  cache(), persist()
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Execution Memory (3.85GB)    â”‚ 48%    â”‚  Shuffles, joins, sorts
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Storage and Execution memory can borrow from each other
(spark.memory.fraction = 0.6, spark.memory.storageFraction = 0.5)

================================================================================
USAGE:
================================================================================

Run this script to see Driver-Executor interaction:

    python 02_driver_executor_demo.py

The script demonstrates:
1. Driver responsibilities (planning, scheduling, coordination)
2. Executor responsibilities (task execution, data storage)
3. Communication patterns (task assignment, result collection)
4. Failure handling (retries, executor failures, lineage)
5. Resource allocation (memory and core distribution)

MONITORING:
Access Spark UI at http://localhost:4040 (or 4041, 4042, etc.)
â€¢ Jobs tab: See jobs, stages, tasks
â€¢ Storage tab: View cached data on executors
â€¢ Executors tab: Monitor executor health and resources
â€¢ SQL tab: View query execution plans

================================================================================
RELATED RESOURCES:
================================================================================

Spark Architecture:
  https://spark.apache.org/docs/latest/cluster-overview.html

Job Scheduling:
  https://spark.apache.org/docs/latest/job-scheduling.html

Configuration:
  https://spark.apache.org/docs/latest/configuration.html

Tuning Guide:
  https://spark.apache.org/docs/latest/tuning.html

Related files in this project:
  â€¢ 01_dag_visualization.py - Shows execution plan visualization
  â€¢ 03_driver_yarn_cluster_interaction.py - YARN cluster lifecycle
  â€¢ 04_standalone_cluster_mode.py - Standalone cluster setup

AUTHOR: PySpark Education Project
LICENSE: Educational Use - MIT License
VERSION: 2.0.0 - Comprehensive Driver-Executor Documentation
CREATED: 2024
UPDATED: 2024 - Added extensive module header and inline comments
================================================================================
"""

import time

from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from pyspark.sql.functions import sum as _sum
from pyspark.sql.functions import udf
from pyspark.sql.types import StringType


def create_spark():
    """
    Create Spark session with explicit configuration.

    This function demonstrates DRIVER INITIALIZATION - the first responsibility
    of the driver process. The SparkSession creation happens on the driver and
    establishes the connection to executors.

    Configuration Breakdown:
    ------------------------
    .appName("DriverExecutorDemo")
      â””â”€> Sets application name (visible in Spark UI and cluster manager)

    .master("local[*]")
      â””â”€> Run locally with as many worker threads as logical cores
          In real clusters: "yarn", "k8s://...", or "spark://..."

    .config("spark.executor.memory", "1g")
      â””â”€> Each executor gets 1GB memory
          Used for: caching data, task execution, shuffle buffers

    .config("spark.driver.memory", "1g")
      â””â”€> Driver gets 1GB memory
          Used for: SparkSession, execution plans, broadcast vars, collect()

    .config("spark.executor.cores", "2")
      â””â”€> Each executor uses 2 CPU cores
          Each core runs 1 task at a time â†’ 2 concurrent tasks per executor

    .config("spark.sql.shuffle.partitions", "8")
      â””â”€> When shuffling (groupBy, join), create 8 output partitions
          Default is 200 (too high for small data)

    .getOrCreate()
      â””â”€> Creates new session or returns existing one
          Only ONE active SparkSession per JVM recommended

    Returns:
    --------
    SparkSession - The entry point for all Spark functionality
    """
    return (
        SparkSession.builder.appName("DriverExecutorDemo")
        .master("local[*]")
        .config("spark.executor.memory", "1g")
        .config("spark.driver.memory", "1g")
        .config("spark.executor.cores", "2")
        .config("spark.sql.shuffle.partitions", "8")
        .getOrCreate()
    )


def demonstrate_driver_responsibilities():
    """
    Show what the driver does.
    """
    print("\n" + "=" * 80)
    print("DRIVER RESPONSIBILITIES")
    print("=" * 80)

    spark = create_spark()

    print("\nğŸ¯ DRIVER TASKS:")
    print("=" * 80)

    # ========================================================================
    # 1. DRIVER RESPONSIBILITY: Maintains SparkSession
    # ========================================================================
    # The driver process holds the SparkSession object in memory. This is
    # the entry point that gives you access to all Spark APIs (SQL, DataFrame,
    # RDD, Streaming, ML). If the driver fails, the SparkSession is lost and
    # the entire application terminates.
    # ========================================================================
    print("\n1ï¸âƒ£  Maintains SparkSession")
    print(f"   SparkSession created: {spark}")
    print(f"   App Name: {spark.sparkContext.appName}")
    print(f"   Master: {spark.sparkContext.master}")

    # ========================================================================
    # 2. DRIVER RESPONSIBILITY: Builds Execution Plans
    # ========================================================================
    # When you write DataFrame operations, NO DATA is processed yet (lazy eval).
    # The driver analyzes your code and builds TWO PLANS:
    #
    # LOGICAL PLAN: What you want to do (high-level operations)
    #   â€¢ Parsed from your Python/Scala/SQL code
    #   â€¢ Optimized by Catalyst optimizer (predicate pushdown, column pruning)
    #
    # PHYSICAL PLAN: How to execute it (low-level operations)
    #   â€¢ Actual execution strategy (scan, filter, project)
    #   â€¢ Chooses join strategies (broadcast, sort-merge, shuffle hash)
    #   â€¢ Determines partition count and distribution
    #
    # The driver builds these plans BEFORE any executor starts working.
    # Use .explain() to see what the driver planned.
    # ========================================================================
    print("\n2ï¸âƒ£  Builds Execution Plans (Logical â†’ Physical)")

    # Create a simple DataFrame (lazy - no execution yet)
    df = spark.range(0, 1000).toDF("id")  # Numbers 0-999

    # Add transformations (still lazy - driver just builds the plan)
    result = df.filter(col("id") > 500).select("id")  # Filter and select

    print("   Logical Plan built by driver:")
    # explain(extended=True) shows the complete plan pipeline:
    # 1. Parsed Logical Plan (your code as-is)
    # 2. Analyzed Logical Plan (with schema info)
    # 3. Optimized Logical Plan (after Catalyst optimization)
    # 4. Physical Plan (actual execution strategy)
    result.explain(extended=True)

    # ========================================================================
    # 3. DRIVER RESPONSIBILITY: Schedules Jobs, Stages, and Tasks
    # ========================================================================
    # The driver breaks your query into a THREE-LEVEL hierarchy:
    #
    # ACTION (e.g., .count(), .show(), .write())
    #   â””â”€> Triggers JOB execution
    #        â””â”€> Job contains STAGES (separated by shuffles)
    #             â””â”€> Each Stage contains TASKS (one per partition)
    #
    # Example: df.groupBy("key").count()
    #   ACTION: .count()
    #   JOB: Single job created
    #   STAGES:
    #     Stage 1: Read data, compute partial counts (map side)
    #     Stage 2: Shuffle and combine counts (reduce side)
    #   TASKS:
    #     Stage 1: If 8 partitions â†’ 8 tasks
    #     Stage 2: If shuffle creates 4 partitions â†’ 4 tasks
    #
    # The driver sends each task to an available executor core.
    # ========================================================================
    print("\n3ï¸âƒ£  Schedules Jobs, Stages, and Tasks")
    print("   Driver breaks query into:")
    print("   â€¢ Jobs (one per action like count, show, write)")
    print("   â€¢ Stages (split at shuffle boundaries like groupBy, join)")
    print("   â€¢ Tasks (one per data partition - unit of parallel work)")
    print("")
    print("   Hierarchy: ACTION â†’ JOB â†’ STAGES â†’ TASKS")
    print("   Example: 8 partitions + no shuffle = 1 stage with 8 tasks")

    # ========================================================================
    # 4. DRIVER RESPONSIBILITY: Tracks Executor Status
    # ========================================================================
    # The driver maintains a registry of ALL executors in the cluster:
    # â€¢ Executor ID and location (host:port)
    # â€¢ Available memory and cores
    # â€¢ Current task assignments
    # â€¢ Heartbeat status (is executor still alive?)
    #
    # The driver uses this info to make scheduling decisions:
    # â€¢ Which executor should run which task?
    # â€¢ Is data locality possible? (send task to executor with data)
    # â€¢ Which executors have failed?
    #
    # defaultParallelism = total cores available across all executors
    # This determines how many tasks can run concurrently.
    # ========================================================================
    print("\n4ï¸âƒ£  Tracks Executor Status")
    print(f"   Active executors: {spark.sparkContext.defaultParallelism}")
    print(
        f"   Default parallelism: {spark.sparkContext.defaultParallelism} concurrent tasks"
    )
    print("   ")
    print("   Driver tracks:")
    print("   â€¢ Which executors are alive")
    print("   â€¢ Available memory and cores per executor")
    print("   â€¢ Current task assignments")
    print("   â€¢ Data locality (which partitions are cached where)")

    # ========================================================================
    # 5. DRIVER RESPONSIBILITY: Collects Results from Executors
    # ========================================================================
    # When you trigger an action (.count(), .collect(), .show()), the driver:
    # 1. Sends tasks to executors
    # 2. Waits for executors to complete tasks
    # 3. Receives results from each task
    # 4. Aggregates results (e.g., sum partial counts)
    # 5. Returns final result to user
    #
    # âš ï¸  WARNING: result.collect() brings ALL data to driver!
    #    â€¢ Driver memory can OOM (Out Of Memory)
    #    â€¢ Use .take(N) or write to disk instead
    #
    # count() is safe - only returns a single Long value
    # ========================================================================
    print("\n5ï¸âƒ£  Collects Results from Executors")

    # Trigger the action - this is when execution actually happens!
    count = result.count()  # Executor tasks run, driver collects counts

    print(f"   Driver received: {count} rows from executors")
    print("   ")
    print("   What happened:")
    print("   1. Driver sent count tasks to executors")
    print("   2. Each executor counted rows in its partitions")
    print("   3. Executors sent partial counts back to driver")
    print("   4. Driver summed partial counts â†’ final result")

    # ========================================================================
    # 6. DRIVER RESPONSIBILITY: Manages Broadcast Variables
    # ========================================================================
    # Broadcast variables efficiently share READ-ONLY data across executors.
    #
    # WITHOUT BROADCAST:
    #   If you use a large lookup dict in a UDF, Spark sends it with EVERY task
    #   Example: 1000 tasks Ã— 100MB dict = 100GB network traffic!
    #
    # WITH BROADCAST:
    #   Driver sends dict ONCE to each executor â†’ reused by all tasks on that executor
    #   Example: 10 executors Ã— 100MB = 1GB network traffic âœ…
    #
    # HOW IT WORKS:
    # 1. Driver holds master copy of broadcast variable
    # 2. Driver uses BitTorrent-like protocol to distribute efficiently
    # 3. Each executor caches broadcast data in memory
    # 4. All tasks on that executor access the same copy
    #
    # USE CASES:
    # â€¢ Lookup dictionaries for enrichment
    # â€¢ Small dimension tables (for broadcast joins)
    # â€¢ ML model parameters
    # â€¢ Configuration data
    # ========================================================================
    print("\n6ï¸âƒ£  Manages Broadcast Variables")

    # Create broadcast variable (driver holds master copy)
    broadcast_var = spark.sparkContext.broadcast({"key": "value"})

    print(f"   Broadcast variable created: {broadcast_var}")
    print("   Driver sends broadcast to all executors")
    print("   ")
    print("   Benefits:")
    print("   â€¢ Sent once per executor (not once per task)")
    print("   â€¢ Reduces network traffic")
    print("   â€¢ Shared memory across tasks on same executor")
    print("   â€¢ Efficient for large read-only data (ML models, lookup tables)")

    print("\nğŸ“Š DRIVER MEMORY USAGE:")
    print("   What the driver stores in memory:")
    print("   â€¢ SparkSession and SparkContext metadata")
    print("   â€¢ Execution plans (DAGs) for all jobs")
    print("   â€¢ Job/stage/task tracking info")
    print("   â€¢ Broadcast variables (master copy)")
    print("   â€¢ Results from collect() âš ï¸  Can cause OOM!")
    print("   â€¢ Accumulated metrics from executors")
    print("")
    print("   Typical driver memory: 2-8GB")
    print("   More if you collect() large results or have many broadcast vars")


def demonstrate_executor_responsibilities():
    """
    Show what executors do.
    """
    print("\n" + "=" * 80)
    print("EXECUTOR RESPONSIBILITIES")
    print("=" * 80)

    spark = create_spark()

    print("\nğŸ”§ EXECUTOR TASKS:")
    print("=" * 80)

    # 1. Run tasks
    print("\n1ï¸âƒ£  Execute Tasks on Partitions")
    df = spark.range(0, 10000).repartition(4)

    # UDF to show which executor is running
    @udf(StringType())
    def get_partition_info(value):
        import os

        return f"PID:{os.getpid()}"

    result = df.withColumn("executor_pid", get_partition_info(col("id")))

    print("   Tasks distributed across executors:")
    result.select("executor_pid").distinct().show()

    # ========================================================================
    # 2. EXECUTOR RESPONSIBILITY: Store Data Partitions in Memory/Disk
    # ========================================================================
    # When you call .cache() or .persist(), data is stored ON EXECUTORS.
    #
    # CACHE WORKFLOW:
    # 1. First action (count, show) computes data
    # 2. Each executor stores its partitions in memory
    # 3. Future actions reuse cached data (no recomputation)
    #
    # STORAGE LEVELS:
    # â€¢ MEMORY_ONLY: Store in memory, drop if not enough space
    # â€¢ MEMORY_AND_DISK: Spill to disk if memory full
    # â€¢ DISK_ONLY: Store only on disk
    # â€¢ OFF_HEAP: Use off-heap memory (outside JVM)
    #
    # Cache is distributed - each executor stores its partitions locally.
    # ========================================================================
    print("\n2ï¸âƒ£  Store Data Partitions in Memory")

    # .cache() marks DataFrame for caching (lazy)
    cached_df = df.cache()

    # .count() triggers computation AND caching
    cached_df.count()  # Materialize cache - data now stored on executors

    print("   Data cached on executors (each stores its partitions)")
    print("   Check Storage tab in Spark UI to see memory usage")
    print("   Future queries will reuse cached data âœ…")

    # 3. Execute computations
    print("\n3ï¸âƒ£  Execute Transformations")

    start = time.time()
    computed = (
        df.filter(col("id") > 1000)
        .withColumn("squared", col("id") * col("id"))
        .filter(col("squared") < 50000000)
    )

    result_count = computed.count()
    exec_time = time.time() - start

    print(f"   Executors processed {result_count} rows")
    print(f"   Execution time: {exec_time:.4f}s")
    print("   All computation done on executors, not driver")

    # 4. Shuffle read/write
    print("\n4ï¸âƒ£  Handle Shuffle Operations")
    grouped = df.groupBy((col("id") % 10).alias("bucket")).count()
    grouped.show()

    print("   Executors wrote shuffle files")
    print("   Executors read shuffle files")
    print("   Check Stages tab for shuffle metrics")

    # 5. Report metrics
    print("\n5ï¸âƒ£  Report Metrics to Driver")
    print("   â€¢ Task completion status")
    print("   â€¢ Shuffle bytes written/read")
    print("   â€¢ Records processed")
    print("   â€¢ Execution time")
    print("   â€¢ Memory usage")

    print("\nğŸ“Š EXECUTOR MEMORY USAGE:")
    print("   â€¢ Cached data partitions")
    print("   â€¢ Task execution memory")
    print("   â€¢ Shuffle buffers")
    print("   â€¢ Broadcast variable copies")

    cached_df.unpersist()


def demonstrate_driver_executor_communication():
    """
    Show communication patterns between driver and executors.
    """
    print("\n" + "=" * 80)
    print("DRIVER â†” EXECUTOR COMMUNICATION")
    print("=" * 80)

    spark = create_spark()

    print("\nğŸ“¡ COMMUNICATION FLOW:")
    print("=" * 80)

    df = spark.range(0, 10000).repartition(4)

    print("\n1ï¸âƒ£  JOB SUBMISSION:")
    print("   Driver â†’ Executors: 'Execute these tasks'")
    print("   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("   â”‚ Driver  â”‚ ------> â”‚ Executor â”‚")
    print("   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print("              Task 0-3 (by partition)")

    print("\n2ï¸âƒ£  TASK EXECUTION:")
    result = df.filter(col("id") > 5000).count()

    print("   Executors: Running tasks in parallel")
    print("   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("   â”‚ Executor â”‚ Task 0: Process partition 0")
    print("   â”‚ Executor â”‚ Task 1: Process partition 1")
    print("   â”‚ Executor â”‚ Task 2: Process partition 2")
    print("   â”‚ Executor â”‚ Task 3: Process partition 3")
    print("   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

    print("\n3ï¸âƒ£  RESULT COLLECTION:")
    print("   Executors â†’ Driver: 'Task complete, here are results'")
    print("   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("   â”‚ Executor â”‚ ------> â”‚ Driver  â”‚")
    print("   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print("           Task results: counts from each partition")

    print(f"\n   Driver aggregates: {result} rows total")

    print("\n4ï¸âƒ£  SHUFFLE COMMUNICATION:")
    grouped = df.groupBy((col("id") % 3).alias("key")).count()
    grouped.show()

    print("   Executors â†” Executors: Shuffle data exchange")
    print("   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("   â”‚ Exec 1   â”‚ <-----> â”‚ Exec 2   â”‚")
    print("   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print("        â†•                    â†•")
    print("   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("   â”‚ Exec 3   â”‚ <-----> â”‚ Exec 4   â”‚")
    print("   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print("   (via shuffle service or executor)")


def demonstrate_failure_handling():
    """
    Show how driver handles executor failures.
    """
    print("\n" + "=" * 80)
    print("FAILURE HANDLING")
    print("=" * 80)

    spark = create_spark()

    print("\nğŸ”„ FAULT TOLERANCE:")
    print("=" * 80)

    print("\n1ï¸âƒ£  Task Failure:")
    print("   â€¢ Executor fails during task")
    print("   â€¢ Driver detects failure")
    print("   â€¢ Driver reschedules task on different executor")
    print("   â€¢ Uses lineage (DAG) to recompute lost data")

    print("\n2ï¸âƒ£  Executor Failure:")
    print("   â€¢ Executor process crashes")
    print("   â€¢ Driver marks executor as lost")
    print("   â€¢ Driver requests new executor from cluster manager")
    print("   â€¢ Reschedules all tasks from failed executor")

    print("\n3ï¸âƒ£  Driver Failure:")
    print("   â€¢ âš ï¸  Driver crash = entire application fails")
    print("   â€¢ No automatic recovery (single point of failure)")
    print("   â€¢ Solution: Use cluster mode + checkpointing")

    print("\n4ï¸âƒ£  Shuffle Data Persistence:")
    df = spark.range(0, 10000).repartition(4)
    grouped = df.groupBy((col("id") % 5).alias("key")).count()
    grouped.show()

    print("   â€¢ Shuffle files written to disk")
    print("   â€¢ Survive executor failures")
    print("   â€¢ External shuffle service keeps data")


def demonstrate_resource_allocation():
    """
    Show resource allocation between driver and executors.
    """
    print("\n" + "=" * 80)
    print("RESOURCE ALLOCATION")
    print("=" * 80)

    spark = create_spark()

    print("\nğŸ’¾ TYPICAL CLUSTER CONFIGURATION:")
    print("=" * 80)

    print(
        """
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    CLUSTER RESOURCES                     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                          â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
    â”‚  â”‚   DRIVER     â”‚  (1 node)                             â”‚
    â”‚  â”‚              â”‚                                        â”‚
    â”‚  â”‚  Memory: 2GB â”‚  â€¢ Plans execution                    â”‚
    â”‚  â”‚  Cores: 2    â”‚  â€¢ Schedules tasks                    â”‚
    â”‚  â”‚              â”‚  â€¢ Collects results                   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
    â”‚         â†“                                                â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚            EXECUTORS (Worker Nodes)              â”‚  â”‚
    â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
    â”‚  â”‚  â”‚ Executor 1 â”‚  â”‚ Executor 2 â”‚  â”‚ Executor 3 â”‚ â”‚  â”‚
    â”‚  â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚ â”‚  â”‚
    â”‚  â”‚  â”‚ Memory: 8GBâ”‚  â”‚ Memory: 8GBâ”‚  â”‚ Memory: 8GBâ”‚ â”‚  â”‚
    â”‚  â”‚  â”‚ Cores: 4   â”‚  â”‚ Cores: 4   â”‚  â”‚ Cores: 4   â”‚ â”‚  â”‚
    â”‚  â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚ â”‚  â”‚
    â”‚  â”‚  â”‚ â€¢ Run tasksâ”‚  â”‚ â€¢ Run tasksâ”‚  â”‚ â€¢ Run tasksâ”‚ â”‚  â”‚
    â”‚  â”‚  â”‚ â€¢ Store dataâ”‚ â”‚ â€¢ Store dataâ”‚ â”‚ â€¢ Store dataâ”‚ â”‚  â”‚
    â”‚  â”‚  â”‚ â€¢ Shuffle  â”‚  â”‚ â€¢ Shuffle  â”‚  â”‚ â€¢ Shuffle  â”‚ â”‚  â”‚
    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    Total Cluster:
    â€¢ Driver: 1 node Ã— 2GB = 2GB
    â€¢ Executors: 3 nodes Ã— 8GB = 24GB
    â€¢ Total: 26GB cluster memory
    â€¢ Parallelism: 3 executors Ã— 4 cores = 12 concurrent tasks
    """
    )

    print("\nâš™ï¸  CONFIGURATION PARAMETERS:")
    print("   --driver-memory 2g")
    print("   --executor-memory 8g")
    print("   --executor-cores 4")
    print("   --num-executors 3")


def main():
    """
    Main execution function.
    """
    print("\n" + "ğŸ¯" * 40)
    print("DRIVER AND EXECUTOR RESPONSIBILITIES")
    print("ğŸ¯" * 40)

    demonstrate_driver_responsibilities()
    demonstrate_executor_responsibilities()
    demonstrate_driver_executor_communication()
    demonstrate_failure_handling()
    demonstrate_resource_allocation()

    print("\n" + "=" * 80)
    print("âœ… DRIVER/EXECUTOR DEMO COMPLETE")
    print("=" * 80)

    print("\nğŸ“š Summary:")
    print("   DRIVER:")
    print("   âœ… Maintains SparkSession")
    print("   âœ… Builds execution plans")
    print("   âœ… Schedules jobs/stages/tasks")
    print("   âœ… Collects results")
    print("   âœ… Manages broadcasts")

    print("\n   EXECUTORS:")
    print("   âœ… Execute tasks on partitions")
    print("   âœ… Store cached data")
    print("   âœ… Perform computations")
    print("   âœ… Handle shuffles")
    print("   âœ… Report metrics")

    spark = SparkSession.builder.getOrCreate()
    spark.stop()


if __name__ == "__main__":
    main()
