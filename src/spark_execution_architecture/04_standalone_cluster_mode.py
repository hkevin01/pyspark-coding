#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
================================================================================
Spark Standalone Cluster Mode - Built-in Clustering
================================================================================

MODULE OVERVIEW:
----------------
Complete guide to Spark's built-in Standalone cluster manager - the simplest
way to deploy Spark on a cluster without requiring Hadoop YARN or Kubernetes.
This demonstrates how Spark's native clustering works, how to set it up, and
how it compares to other cluster managers.

PURPOSE:
--------
Learn Spark Standalone clustering:
- How to set up a Standalone cluster (Master + Workers)
- Application submission and execution
- Resource allocation and management
- Differences from YARN/Kubernetes
- When to use Standalone mode

TARGET AUDIENCE:
----------------
- Developers learning Spark clustering
- Teams wanting simple cluster deployment
- Users migrating from local to cluster mode
- Anyone needing quick cluster setup without Hadoop/K8s

SPARK STANDALONE ARCHITECTURE:
===============================

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    SPARK STANDALONE CLUSTER                  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚                    MASTER NODE                       â”‚  â”‚
    â”‚  â”‚  (spark://master-host:7077)                          â”‚  â”‚
    â”‚  â”‚                                                       â”‚  â”‚
    â”‚  â”‚  Responsibilities:                                    â”‚  â”‚
    â”‚  â”‚  â€¢ Accept application submissions                     â”‚  â”‚
    â”‚  â”‚  â€¢ Manage worker registration                         â”‚  â”‚
    â”‚  â”‚  â€¢ Allocate resources to applications                 â”‚  â”‚
    â”‚  â”‚  â€¢ Monitor worker/executor health                     â”‚  â”‚
    â”‚  â”‚  â€¢ Provide Web UI (port 8080)                         â”‚  â”‚
    â”‚  â”‚  â€¢ Handle failover (if HA configured)                 â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚         â”‚                    â”‚                    â”‚         â”‚
    â”‚         â†“                    â†“                    â†“         â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
    â”‚  â”‚  WORKER 1   â”‚      â”‚  WORKER 2   â”‚      â”‚  WORKER 3   â”‚â”‚
    â”‚  â”‚             â”‚      â”‚             â”‚      â”‚             â”‚â”‚
    â”‚  â”‚  Resources: â”‚      â”‚  Resources: â”‚      â”‚  Resources: â”‚â”‚
    â”‚  â”‚  â€¢ 8 cores  â”‚      â”‚  â€¢ 8 cores  â”‚      â”‚  â€¢ 8 cores  â”‚â”‚
    â”‚  â”‚  â€¢ 16GB RAM â”‚      â”‚  â€¢ 16GB RAM â”‚      â”‚  â€¢ 16GB RAM â”‚â”‚
    â”‚  â”‚             â”‚      â”‚             â”‚      â”‚             â”‚â”‚
    â”‚  â”‚  Executors: â”‚      â”‚  Executors: â”‚      â”‚  Executors: â”‚â”‚
    â”‚  â”‚  [Exec 1]   â”‚      â”‚  [Exec 3]   â”‚      â”‚  [Exec 5]   â”‚â”‚
    â”‚  â”‚  [Exec 2]   â”‚      â”‚  [Exec 4]   â”‚      â”‚  [Exec 6]   â”‚â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

HOW STANDALONE MODE WORKS:
===========================

STARTUP SEQUENCE:
-----------------
1. Start Master:
   $ $SPARK_HOME/sbin/start-master.sh
   - Master starts on port 7077 (default)
   - Web UI available at http://master:8080
   - Master URL: spark://master-host:7077

2. Start Workers:
   $ $SPARK_HOME/sbin/start-worker.sh spark://master-host:7077
   - Worker connects to Master
   - Registers available resources (cores, memory)
   - Starts heartbeat mechanism
   - Web UI available at http://worker:8081

3. Submit Application:
   $ spark-submit --master spark://master-host:7077 \\
                  --deploy-mode client \\
                  app.py

RESOURCE ALLOCATION MODES:
===========================

1. CORES ALLOCATION:
--------------------
--total-executor-cores 24  # Total cores across ALL executors
--executor-cores 4          # Cores per executor
Result: 24 / 4 = 6 executors

2. MEMORY ALLOCATION:
---------------------
--executor-memory 4g        # Memory per executor
Workers must have enough memory to satisfy requests

3. SPREAD VS CONSOLIDATE:
--------------------------
spark.deploy.spreadOut = true (default)
- Spreads executors across all available workers
- Good for: Data locality, fault tolerance
- Example: 6 executors on 3 workers = 2 per worker

spark.deploy.spreadOut = false
- Packs executors on fewer workers
- Good for: Resource efficiency, fewer JVMs
- Example: 6 executors might go on 2 workers only

APPLICATION SUBMISSION FLOW:
=============================

CLIENT MODE (default):
----------------------
1. spark-submit connects to Master
2. Master allocates resources on Workers
3. Workers launch Executors
4. Driver (on client machine) connects to Executors
5. Application runs
6. Results return to Driver on client

CLUSTER MODE:
-------------
1. spark-submit connects to Master
2. Master selects a Worker to run Driver
3. Worker launches Driver in executor process
4. Driver requests more Executors from Master
5. Workers launch additional Executors
6. Application runs entirely in cluster
7. Client can disconnect

KEY DIFFERENCES FROM YARN/KUBERNETES:
======================================

STANDALONE vs YARN:
-------------------
                   Standalone          YARN
Setup             Simple              Complex (needs Hadoop)
Multi-tenancy     Basic               Advanced (queues, ACLs)
Resource Sharing  Per-app             Fine-grained
Dynamic Alloc     Limited             Full support
Security          Basic               Kerberos, ACLs
Monitoring        Web UI              ResourceManager UI
Failover          Optional HA         Built-in HA

STANDALONE vs KUBERNETES:
-------------------------
                   Standalone          Kubernetes
Setup             Simple              Moderate (needs K8s)
Containers        No                  Yes (pods)
Scaling           Manual              Auto-scaling
Orchestration     Basic               Advanced
Cloud Native      No                  Yes
Resource Limits   Soft                Hard (cgroups)

WHEN TO USE STANDALONE:
=======================

âœ… GOOD FOR:
- Development and testing
- Small to medium clusters (< 50 nodes)
- Single organization/team
- Quick cluster setup
- Learning Spark clustering
- Don't have Hadoop/K8s infrastructure

âŒ NOT GOOD FOR:
- Multi-tenant production environments
- Need fine-grained resource sharing
- Require advanced security (Kerberos)
- Need container isolation
- Cloud-native deployments

CONFIGURATION DEEP DIVE:
=========================

MASTER CONFIGURATION:
---------------------
spark.deploy.defaultCores = 1
  - Cores given to each application by default
  - Set to limit resource hogging

SPARK_MASTER_OPTS:
  -Dspark.deploy.defaultCores=8
  -Dspark.worker.timeout=60
  -Dspark.deploy.retainedApplications=200
  -Dspark.deploy.retainedDrivers=200

WORKER CONFIGURATION:
---------------------
SPARK_WORKER_CORES = 8
  - Number of cores available on this worker
  - Usually set to physical core count

SPARK_WORKER_MEMORY = 16g
  - Memory available for executors
  - Leave some for OS (typically 1-2GB)

SPARK_WORKER_INSTANCES = 1
  - Number of worker instances per machine
  - Usually 1, but can run multiple for testing

SPARK_WORKER_DIR = /var/spark/work
  - Working directory for executor logs

EXECUTOR CONFIGURATION:
-----------------------
spark.executor.cores = 4
  - Cores per executor (parallelism)
  - Too high: memory contention
  - Too low: underutilization

spark.executor.memory = 4g
  - Heap size per executor
  - Actual container size = memory + memoryOverhead

spark.executor.memoryOverhead = 0.1 (10%)
  - Off-heap memory for VM overheads
  - Min 384MB

HIGH AVAILABILITY (HA) SETUP:
==============================

ZOOKEEPER-BASED HA:
-------------------
Multiple Master nodes with ZooKeeper coordination

Configuration:
spark.deploy.recoveryMode = ZOOKEEPER
spark.deploy.zookeeper.url = zk1:2181,zk2:2181,zk3:2181
spark.deploy.zookeeper.dir = /spark

Benefits:
âœ… Automatic failover
âœ… No single point of failure
âœ… State persisted in ZooKeeper

Setup:
1. Start ZooKeeper ensemble
2. Start multiple Masters with same config
3. Workers connect to all Masters
4. Active Master elected via ZooKeeper
5. If Active fails, Standby becomes Active

FILESYSTEM-BASED HA:
--------------------
Single Master with state stored on shared filesystem (NFS, HDFS)

Configuration:
spark.deploy.recoveryMode = FILESYSTEM
spark.deploy.recoveryDirectory = hdfs://namenode/spark/recovery

Benefits:
âœ… Simpler than ZooKeeper
âœ… Master can restart and recover state

Limitations:
âŒ Manual restart required
âŒ Longer recovery time

MONITORING AND DEBUGGING:
==========================

WEB UIs:
--------
Master UI: http://master:8080
  - Active/completed applications
  - Worker list and resources
  - Application history

Worker UI: http://worker:8081
  - Running executors
  - Resource usage
  - Logs

Application UI: http://driver:4040
  - Jobs, stages, tasks
  - Storage (cached data)
  - Environment, executors

METRICS:
--------
spark.metrics.conf = /path/to/metrics.properties
  - Enable metrics reporting
  - Graphite, Ganglia, Prometheus

LOG FILES:
----------
Master logs: $SPARK_HOME/logs/spark-*-master-*.out
Worker logs: $SPARK_HOME/logs/spark-*-worker-*.out
Executor logs: $SPARK_WORKER_DIR/app-*/executor-*.log

RESOURCE ALLOCATION EXAMPLES:
==============================

EXAMPLE 1: Basic Setup
----------------------
Cluster: 3 workers Ã— 8 cores Ã— 16GB = 24 cores, 48GB

Request:
--total-executor-cores 12
--executor-memory 4g

Result:
- 12 cores allocated across executors
- Each executor gets 4GB
- With default 1 core per executor: 12 executors
- With --executor-cores 4: 3 executors
- Spread across all 3 workers

EXAMPLE 2: Memory-Intensive
----------------------------
Cluster: 3 workers Ã— 8 cores Ã— 64GB = 24 cores, 192GB

Request:
--executor-memory 16g
--executor-cores 2
--total-executor-cores 6

Result:
- 6 cores / 2 = 3 executors
- Each: 16GB memory, 2 cores
- Total: 48GB memory, 6 cores
- Leaves resources for other apps

EXAMPLE 3: CPU-Intensive
-------------------------
Cluster: 3 workers Ã— 16 cores Ã— 32GB = 48 cores, 96GB

Request:
--total-executor-cores 48
--executor-cores 4
--executor-memory 2g

Result:
- 48 cores / 4 = 12 executors
- Each: 2GB memory, 4 cores
- Total: 24GB memory, 48 cores
- Maximizes CPU utilization

USAGE:
------
# Start cluster (on each machine):
$SPARK_HOME/sbin/start-master.sh  # On master node
$SPARK_HOME/sbin/start-worker.sh spark://master:7077  # On worker nodes

# Submit application:
spark-submit --master spark://master:7077 \\
             --deploy-mode client \\
             --total-executor-cores 12 \\
             --executor-memory 4g \\
             04_standalone_cluster_mode.py

# Stop cluster:
$SPARK_HOME/sbin/stop-worker.sh  # On workers
$SPARK_HOME/sbin/stop-master.sh  # On master

RELATED RESOURCES:
------------------
- Standalone Mode: https://spark.apache.org/docs/latest/spark-standalone.html
- Submitting Applications: https://spark.apache.org/docs/latest/submitting-applications.html
- Monitoring: https://spark.apache.org/docs/latest/monitoring.html

AUTHOR: PySpark Education Project
LICENSE: Educational Use - MIT License
VERSION: 1.0.0
CREATED: December 13, 2025

================================================================================
"""

# ============================================================================
# STANDARD LIBRARY IMPORTS
# ============================================================================
import os
import sys
import time
from datetime import datetime

# ============================================================================
# THIRD-PARTY IMPORTS
# ============================================================================
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, sum as _sum, avg, max as _max
from pyspark import SparkConf


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def print_section(title):
    """Print formatted section header."""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80 + "\n")


def print_subsection(title):
    """Print formatted subsection header."""
    print(f"\n{'â”€' * 80}")
    print(f"  {title}")
    print('â”€' * 80)


# ============================================================================
# STANDALONE CLUSTER SETUP SIMULATION
# ============================================================================

def demonstrate_cluster_setup():
    """
    Demonstrate how to set up a Spark Standalone cluster.
    
    WHAT THIS SHOWS:
    ----------------
    The complete process of setting up Master and Worker nodes in a
    Standalone cluster, including configuration and startup.
    
    CLUSTER TOPOLOGY:
    -----------------
    1 Master node + 3 Worker nodes
    
    Master:
    - hostname: spark-master
    - cores: 4 (for master process, not for executors)
    - memory: 4GB
    - ports: 7077 (RPC), 8080 (Web UI)
    
    Workers (each):
    - cores: 8 (available for executors)
    - memory: 16GB
    - ports: 8081, 8082, 8083 (Web UIs)
    """
    print_section("STANDALONE CLUSTER SETUP")
    
    # ========================================================================
    # STEP 1: START MASTER
    # ========================================================================
    # WHAT HAPPENS:
    # When you run: $SPARK_HOME/sbin/start-master.sh
    #
    # 1. Script reads configuration from:
    #    - $SPARK_HOME/conf/spark-env.sh
    #    - $SPARK_HOME/conf/spark-defaults.conf
    #
    # 2. Master process starts:
    #    - Class: org.apache.spark.deploy.master.Master
    #    - Binds to port 7077 for RPC (application submissions)
    #    - Binds to port 8080 for Web UI
    #    - Starts REST server (port 6066) for submissions
    #
    # 3. Master initializes:
    #    - Creates empty worker registry
    #    - Creates empty application registry
    #    - Starts heartbeat checker thread
    #    - Starts resource scheduler thread
    #
    # 4. Master is ready:
    #    - URL: spark://spark-master:7077
    #    - Web UI: http://spark-master:8080
    #    - Waiting for worker registrations
    # ========================================================================
    print("Step 1ï¸âƒ£: Starting Spark Master")
    print("   Command: $SPARK_HOME/sbin/start-master.sh\n")
    
    print("   ğŸ“‹ Master Configuration (spark-env.sh):")
    print("      export SPARK_MASTER_HOST=spark-master")
    print("      export SPARK_MASTER_PORT=7077")
    print("      export SPARK_MASTER_WEBUI_PORT=8080")
    print("      export SPARK_MASTER_OPTS='-Dspark.deploy.defaultCores=4'")
    print("")
    
    print("   ğŸš€ Master Starting...")
    print("      â€¢ Reading configuration files")
    print("      â€¢ Binding to spark-master:7077 (RPC)")
    print("      â€¢ Binding to spark-master:8080 (Web UI)")
    print("      â€¢ Binding to spark-master:6066 (REST)")
    print("      â€¢ Initializing worker registry")
    print("      â€¢ Starting heartbeat checker")
    print("      â€¢ Starting resource scheduler")
    print("")
    
    print("   âœ… Master Started Successfully!")
    print("      â€¢ Master URL: spark://spark-master:7077")
    print("      â€¢ Web UI: http://spark-master:8080")
    print("      â€¢ Status: ALIVE")
    print("      â€¢ Workers: 0 (waiting for registrations)")
    print("")
    
    # ========================================================================
    # STEP 2: START WORKERS
    # ========================================================================
    # WHAT HAPPENS:
    # When you run: $SPARK_HOME/sbin/start-worker.sh spark://spark-master:7077
    #
    # 1. Script reads configuration:
    #    - SPARK_WORKER_CORES (available cores)
    #    - SPARK_WORKER_MEMORY (available memory)
    #    - SPARK_WORKER_DIR (work directory for logs)
    #
    # 2. Worker process starts:
    #    - Class: org.apache.spark.deploy.worker.Worker
    #    - Connects to Master at spark://spark-master:7077
    #    - Sends RegisterWorker message
    #
    # 3. Master receives registration:
    #    - Validates worker information
    #    - Assigns worker ID
    #    - Adds to worker registry
    #    - Sends RegisteredWorker response
    #
    # 4. Worker starts services:
    #    - Binds Web UI (port 8081, 8082, 8083...)
    #    - Starts heartbeat thread (sends to Master every 60s)
    #    - Starts executor launcher thread
    #    - Creates work directory
    #
    # 5. Worker is ready:
    #    - Registered with Master
    #    - Resources advertised
    #    - Ready to launch executors
    # ========================================================================
    print("Step 2ï¸âƒ£: Starting Spark Workers")
    print("   Command: $SPARK_HOME/sbin/start-worker.sh spark://spark-master:7077\n")
    
    workers = [
        ("worker-1", "192.168.1.101", 8, "16g", 8081),
        ("worker-2", "192.168.1.102", 8, "16g", 8082),
        ("worker-3", "192.168.1.103", 8, "16g", 8083),
    ]
    
    for worker_name, ip, cores, memory, webui_port in workers:
        print(f"   ğŸ”§ Starting {worker_name} ({ip})...")
        print(f"      Configuration:")
        print(f"         SPARK_WORKER_CORES={cores}")
        print(f"         SPARK_WORKER_MEMORY={memory}")
        print(f"         SPARK_WORKER_DIR=/var/spark/work")
        print("")
        
        print(f"      Registration Process:")
        print(f"         1. Worker connects to Master: spark://spark-master:7077")
        print(f"         2. Worker sends: RegisterWorker(")
        print(f"               id={worker_name},")
        print(f"               host={ip},")
        print(f"               port=7078,")
        print(f"               cores={cores},")
        print(f"               memory={memory}")
        print(f"            )")
        print(f"         3. Master validates and assigns ID")
        print(f"         4. Master sends: RegisteredWorker(workerId=worker-xyz)")
        print(f"         5. Worker starts heartbeat every 60s")
        print("")
        
        print(f"      âœ… {worker_name} Registered!")
        print(f"         â€¢ Worker ID: worker-{worker_name}")
        print(f"         â€¢ Web UI: http://{ip}:{webui_port}")
        print(f"         â€¢ Available: {cores} cores, {memory}")
        print(f"         â€¢ Status: ALIVE")
        print("")
    
    print("   ğŸ“Š Cluster Resources Summary:")
    print("      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("      â”‚ Worker       â”‚ Cores   â”‚ Memory   â”‚ Status             â”‚")
    print("      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    for worker_name, ip, cores, memory, _ in workers:
        print(f"      â”‚ {worker_name:<12} â”‚ {cores:<7} â”‚ {memory:<8} â”‚ {'ALIVE':<18} â”‚")
    print("      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print(f"      â”‚ {'TOTAL':<12} â”‚ {24:<7} â”‚ {'48g':<8} â”‚ {'3 workers online':<18} â”‚")
    print("      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print("")
    
    print("   âœ… Standalone Cluster Ready!")
    print("      â€¢ Master: spark://spark-master:7077")
    print("      â€¢ Workers: 3 active")
    print("      â€¢ Total Resources: 24 cores, 48GB memory")
    print("      â€¢ Ready to accept applications")


# ============================================================================
# APPLICATION SUBMISSION
# ============================================================================

def demonstrate_application_submission():
    """
    Demonstrate submitting an application to Standalone cluster.
    
    WHAT THIS SHOWS:
    ----------------
    Complete flow from spark-submit command through executor launch,
    showing all Master-Worker interactions.
    
    SUBMISSION MODES:
    -----------------
    CLIENT MODE:
    - Driver runs on machine where spark-submit executed
    - Driver connects directly to executors
    - Good for interactive work
    - Client must stay connected
    
    CLUSTER MODE:
    - Driver runs on a worker node
    - Cluster runs driver as supervised process
    - Good for production
    - Client can disconnect after submission
    """
    print_section("APPLICATION SUBMISSION TO STANDALONE CLUSTER")
    
    # ========================================================================
    # CLIENT MODE SUBMISSION
    # ========================================================================
    # COMMAND:
    # spark-submit --master spark://spark-master:7077 \\
    #              --deploy-mode client \\
    #              --total-executor-cores 12 \\
    #              --executor-memory 4g \\
    #              --executor-cores 2 \\
    #              my_app.py
    #
    # WHAT HAPPENS:
    # 1. spark-submit parses arguments
    # 2. Driver starts on client machine (where you ran command)
    # 3. Driver connects to Master at spark://spark-master:7077
    # 4. Driver requests executors: 12 cores total, 4GB each, 2 cores/executor
    # 5. Master calculates: 12 cores / 2 cores per executor = 6 executors
    # 6. Master allocates executors across workers
    # 7. Workers launch executor JVM processes
    # 8. Executors connect back to Driver
    # 9. Application runs
    # ========================================================================
    print("Submission Mode: CLIENT MODE")
    print("Command:")
    print("   spark-submit --master spark://spark-master:7077 \\")
    print("                --deploy-mode client \\")
    print("                --total-executor-cores 12 \\")
    print("                --executor-memory 4g \\")
    print("                --executor-cores 2 \\")
    print("                my_app.py")
    print("")
    
    print("Step 1ï¸âƒ£: Driver Initialization (on client machine)")
    print("   â€¢ SparkContext created")
    print("   â€¢ Connects to Master: spark://spark-master:7077")
    print("   â€¢ Sends application registration:")
    print("      - App Name: MySparkApp")
    print("      - Cores requested: 12")
    print("      - Memory per executor: 4g")
    print("      - Cores per executor: 2")
    print("")
    
    print("Step 2ï¸âƒ£: Master Processes Request")
    print("   â€¢ Master receives registration")
    print("   â€¢ Assigns application ID: app-20251213143000-0001")
    print("   â€¢ Calculates executor requirements:")
    print("      - Total cores: 12")
    print("      - Cores per executor: 2")
    print("      - Number of executors: 12 / 2 = 6 executors")
    print("      - Memory per executor: 4GB")
    print("")
    
    print("   â€¢ Master checks available resources:")
    print("      - worker-1: 8 cores, 16GB available")
    print("      - worker-2: 8 cores, 16GB available")
    print("      - worker-3: 8 cores, 16GB available")
    print("      - Total: 24 cores, 48GB (sufficient!)")
    print("")
    
    print("   â€¢ Master allocates executors (spreadOut=true):")
    print("      - Spreads across all workers for fault tolerance")
    print("      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("      â”‚ Worker   â”‚ Executor ID  â”‚ Cores â”‚ Memory â”‚")
    print("      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print("      â”‚ worker-1 â”‚ executor-0   â”‚ 2     â”‚ 4GB    â”‚")
    print("      â”‚ worker-1 â”‚ executor-1   â”‚ 2     â”‚ 4GB    â”‚")
    print("      â”‚ worker-2 â”‚ executor-2   â”‚ 2     â”‚ 4GB    â”‚")
    print("      â”‚ worker-2 â”‚ executor-3   â”‚ 2     â”‚ 4GB    â”‚")
    print("      â”‚ worker-3 â”‚ executor-4   â”‚ 2     â”‚ 4GB    â”‚")
    print("      â”‚ worker-3 â”‚ executor-5   â”‚ 2     â”‚ 4GB    â”‚")
    print("      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print("")
    
    print("Step 3ï¸âƒ£: Workers Launch Executors")
    print("   worker-1:")
    print("      â€¢ Receives LaunchExecutor(executor-0, 2 cores, 4GB)")
    print("      â€¢ Creates work directory: /var/spark/work/app-001/0")
    print("      â€¢ Launches JVM:")
    print("         java -Xmx4g -cp spark-assembly.jar \\")
    print("              org.apache.spark.executor.CoarseGrainedExecutorBackend \\")
    print("              --driver-url spark://CoarseGrainedScheduler@client:12345 \\")
    print("              --executor-id 0 --cores 2 --app-id app-001")
    print("      â€¢ Executor connects to Driver")
    print("      âœ… executor-0 running on worker-1")
    print("")
    
    print("      â€¢ (Same process for executor-1)")
    print("      âœ… executor-1 running on worker-1")
    print("")
    
    print("   worker-2:")
    print("      âœ… executor-2 running on worker-2")
    print("      âœ… executor-3 running on worker-2")
    print("")
    
    print("   worker-3:")
    print("      âœ… executor-4 running on worker-3")
    print("      âœ… executor-5 running on worker-3")
    print("")
    
    print("Step 4ï¸âƒ£: Driver Ready for Execution")
    print("   â€¢ All 6 executors registered with Driver")
    print("   â€¢ Total resources available:")
    print("      - 12 cores (6 executors Ã— 2 cores)")
    print("      - 24GB memory (6 executors Ã— 4GB)")
    print("   â€¢ Driver can now schedule tasks")
    print("   â€¢ Max parallelism: 12 tasks at once")
    print("")


# ============================================================================
# CREATE DEMONSTRATION SPARK SESSION
# ============================================================================

def create_spark_session():
    """
    Create SparkSession configured for Standalone mode.
    
    WHAT THIS DEMONSTRATES:
    -----------------------
    In this demo, we use local mode to simulate Standalone behavior.
    In production, you would use:
        .master("spark://spark-master:7077")
    
    CONFIGURATION EXPLAINED:
    ------------------------
    spark.cores.max = 12
      - Maximum cores to use across ALL executors
      - In Standalone: hard limit, won't use more
      - Equivalent to --total-executor-cores
    
    spark.executor.cores = 2
      - Cores per executor
      - Controls parallelism per executor
      - With 12 max cores: 12/2 = 6 executors
    
    spark.executor.memory = 4g
      - Heap memory per executor
      - Actual memory = 4g + overhead (10% = 400MB)
      - Total = 4.4GB per executor container
    
    spark.deploy.spreadOut = true (default)
      - Spread executors across workers
      - false: pack on fewer workers
    """
    print_section("CREATING SPARK SESSION (STANDALONE MODE)")
    
    print("Configuration for Standalone Cluster:")
    print("   spark.master = spark://spark-master:7077")
    print("   spark.cores.max = 12")
    print("   spark.executor.cores = 2")
    print("   spark.executor.memory = 4g")
    print("   spark.deploy.spreadOut = true")
    print("")
    
    # For demo purposes, use local mode
    print("â„¹ï¸  Demo Mode: Using local[12] to simulate 12-core cluster")
    print("")
    
    spark = (SparkSession.builder
        .appName("StandaloneClusterDemo")
        .master("local[12]")  # Simulates 12 cores
        .config("spark.sql.shuffle.partitions", "12")  # Match core count
        .getOrCreate())
    
    print("âœ… SparkSession Created")
    print(f"   â€¢ Spark Version: {spark.version}")
    print(f"   â€¢ Master: {spark.sparkContext.master}")
    print(f"   â€¢ App ID: {spark.sparkContext.applicationId}")
    print(f"   â€¢ Default Parallelism: {spark.sparkContext.defaultParallelism}")
    print("")
    
    return spark


# ============================================================================
# RESOURCE ALLOCATION DEMONSTRATION
# ============================================================================

def demonstrate_resource_allocation(spark):
    """
    Demonstrate how Standalone cluster allocates resources during execution.
    
    WHAT THIS SHOWS:
    ----------------
    How tasks are distributed across executors and how Spark uses the
    allocated resources (12 cores across 6 executors).
    
    TASK SCHEDULING:
    ----------------
    1. Action triggers job
    2. Driver creates stages
    3. Driver creates tasks (1 per partition)
    4. Driver schedules tasks on executor cores
    5. Each executor runs up to 'cores' tasks in parallel
    6. With 6 executors Ã— 2 cores = 12 parallel tasks max
    """
    print_section("RESOURCE ALLOCATION & TASK EXECUTION")
    
    print("Creating sample dataset with 12 partitions...")
    print("   df = spark.range(0, 1_200_000).repartition(12)")
    print("")
    
    # Create DataFrame with 12 partitions (matches our 12 cores)
    df = spark.range(0, 1_200_000).repartition(12)
    
    print("âœ… DataFrame created with 12 partitions")
    print("   â€¢ Each partition: ~100,000 rows")
    print("   â€¢ 1 task will be created per partition")
    print("   â€¢ 12 tasks total")
    print("")
    
    print("Applying transformations:")
    print("   df_filtered = df.filter(col('id') > 500_000)")
    print("   df_squared = df_filtered.withColumn('squared', col('id') * col('id'))")
    print("")
    
    df_filtered = df.filter(col("id") > 500_000)
    df_squared = df_filtered.withColumn("squared", col("id") * col("id"))
    
    print("Triggering action: count()")
    print("")
    print("Driver's Scheduling Plan:")
    print("   â€¢ Job: count()")
    print("   â€¢ Stages: 1 (no shuffle needed)")
    print("   â€¢ Tasks: 12 (one per partition)")
    print("")
    
    print("Task Distribution Across Executors:")
    print("   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("   â”‚ Executor    â”‚ Worker   â”‚ Tasks Assigned  â”‚ Parallelism  â”‚")
    print("   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print("   â”‚ executor-0  â”‚ worker-1 â”‚ task-0, task-6  â”‚ 2 at a time  â”‚")
    print("   â”‚ executor-1  â”‚ worker-1 â”‚ task-1, task-7  â”‚ 2 at a time  â”‚")
    print("   â”‚ executor-2  â”‚ worker-2 â”‚ task-2, task-8  â”‚ 2 at a time  â”‚")
    print("   â”‚ executor-3  â”‚ worker-2 â”‚ task-3, task-9  â”‚ 2 at a time  â”‚")
    print("   â”‚ executor-4  â”‚ worker-3 â”‚ task-4, task-10 â”‚ 2 at a time  â”‚")
    print("   â”‚ executor-5  â”‚ worker-3 â”‚ task-5, task-11 â”‚ 2 at a time  â”‚")
    print("   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print("")
    
    print("Execution Timeline:")
    print("   Wave 1 (tasks 0-11 start simultaneously):")
    print("      â€¢ All 6 executors start working")
    print("      â€¢ 12 tasks running in parallel")
    print("      â€¢ Using all 12 cores")
    print("")
    
    start_time = time.time()
    result = df_squared.count()
    execution_time = time.time() - start_time
    
    print(f"âœ… Execution Complete!")
    print(f"   â€¢ Result: {result:,} rows")
    print(f"   â€¢ Execution Time: {execution_time:.4f} seconds")
    print(f"   â€¢ All 12 tasks completed")
    print(f"   â€¢ Peak parallelism: 12 tasks")
    print("")
    
    print("Resource Utilization:")
    print("   â€¢ Cores: 12/12 used (100%)")
    print("   â€¢ Executors: 6/6 used (100%)")
    print("   â€¢ Workers: 3/3 used (100%)")
    print("   â€¢ Efficient distribution across cluster")


# ============================================================================
# MONITORING AND WEB UI
# ============================================================================

def demonstrate_monitoring():
    """
    Demonstrate monitoring capabilities in Standalone mode.
    
    WHAT THIS SHOWS:
    ----------------
    How to monitor your Standalone cluster and running applications
    using the built-in Web UIs.
    
    WEB UIs AVAILABLE:
    ------------------
    1. Master Web UI (port 8080)
    2. Worker Web UIs (ports 8081, 8082, 8083)
    3. Application Web UI (port 4040)
    4. History Server (port 18080)
    """
    print_section("MONITORING STANDALONE CLUSTER")
    
    print("Available Web UIs:")
    print("")
    
    print("1ï¸âƒ£  Master Web UI: http://spark-master:8080")
    print("   Information Available:")
    print("      â€¢ Cluster Summary")
    print("         - Workers: 3")
    print("         - Cores: 24 total, 12 used, 12 free")
    print("         - Memory: 48GB total, 24GB used, 24GB free")
    print("      â€¢ Running Applications")
    print("         - App ID, Name, User")
    print("         - Cores used, Memory used")
    print("         - Duration, State")
    print("      â€¢ Completed Applications")
    print("         - Application history")
    print("         - Final status (FINISHED, FAILED, KILLED)")
    print("      â€¢ Workers List")
    print("         - Worker ID, Address")
    print("         - State (ALIVE, DEAD, DECOMMISSIONED)")
    print("         - Cores, Memory")
    print("         - Running executors")
    print("")
    
    print("2ï¸âƒ£  Worker Web UIs:")
    print("   worker-1: http://192.168.1.101:8081")
    print("   worker-2: http://192.168.1.102:8082")
    print("   worker-3: http://192.168.1.103:8083")
    print("")
    print("   Information Per Worker:")
    print("      â€¢ Worker Summary")
    print("         - Worker ID, State")
    print("         - Cores: 8 total, 4 used, 4 free")
    print("         - Memory: 16GB total, 8GB used, 8GB free")
    print("      â€¢ Running Executors")
    print("         - Executor ID, Application")
    print("         - Cores used, Memory used")
    print("         - Logs (stdout, stderr)")
    print("      â€¢ Finished Executors")
    print("         - Exit code, duration")
    print("")
    
    print("3ï¸âƒ£  Application Web UI: http://driver:4040")
    print("   Available During Application Run:")
    print("      â€¢ Jobs")
    print("         - Active, completed, failed jobs")
    print("         - Duration, stages, tasks")
    print("      â€¢ Stages")
    print("         - Active, pending, completed stages")
    print("         - Input/output size")
    print("         - Shuffle read/write")
    print("         - Task metrics")
    print("      â€¢ Storage")
    print("         - Cached RDDs/DataFrames")
    print("         - Memory used per RDD")
    print("         - Partitions cached")
    print("      â€¢ Environment")
    print("         - Spark properties")
    print("         - System properties")
    print("         - Classpath entries")
    print("      â€¢ Executors")
    print("         - Executor list")
    print("         - Memory usage")
    print("         - Task time, GC time")
    print("         - Shuffle read/write")
    print("         - Thread dump")
    print("      â€¢ SQL")
    print("         - Executed SQL queries")
    print("         - Physical plans")
    print("         - Query duration")
    print("")
    
    print("4ï¸âƒ£  History Server: http://spark-master:18080")
    print("   For Completed Applications:")
    print("      â€¢ View all past applications")
    print("      â€¢ Same views as Application UI")
    print("      â€¢ Requires event logging enabled:")
    print("         spark.eventLog.enabled=true")
    print("         spark.eventLog.dir=hdfs://namenode/spark-logs")
    print("")
    
    print("Monitoring Best Practices:")
    print("   âœ… Check Master UI for cluster health")
    print("   âœ… Monitor Worker UIs for resource usage")
    print("   âœ… Use Application UI during development")
    print("   âœ… Enable History Server for production")
    print("   âœ… Set up external monitoring (Prometheus, Grafana)")
    print("   âœ… Configure alerts for worker failures")


# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """
    Main function demonstrating Spark Standalone cluster.
    """
    print("\n" + "ğŸ¯" * 40)
    print("SPARK STANDALONE CLUSTER MODE")
    print("Built-in Clustering Without YARN/Kubernetes")
    print("ğŸ¯" * 40)
    
    # Demonstrate cluster setup
    demonstrate_cluster_setup()
    
    # Demonstrate application submission
    demonstrate_application_submission()
    
    # Create Spark session
    spark = create_spark_session()
    
    # Demonstrate resource allocation
    demonstrate_resource_allocation(spark)
    
    # Demonstrate monitoring
    demonstrate_monitoring()
    
    # Cleanup
    spark.stop()
    
    print("\n" + "=" * 80)
    print("âœ… STANDALONE CLUSTER DEMONSTRATION COMPLETE")
    print("=" * 80)
    
    print("\nğŸ“š Summary:")
    print("   âœ… Standalone = Simple, built-in clustering")
    print("   âœ… Master manages resources and scheduling")
    print("   âœ… Workers launch and manage executors")
    print("   âœ… No Hadoop or Kubernetes required")
    print("   âœ… Perfect for dev/test and small clusters")
    
    print("\nğŸ”— Key Commands:")
    print("   Start Master: $SPARK_HOME/sbin/start-master.sh")
    print("   Start Worker: $SPARK_HOME/sbin/start-worker.sh spark://master:7077")
    print("   Submit App:   spark-submit --master spark://master:7077 app.py")
    print("   Stop All:     $SPARK_HOME/sbin/stop-all.sh")
    
    print("\nğŸ’¡ When to Use Standalone:")
    print("   âœ… Learning Spark clustering")
    print("   âœ… Development and testing")
    print("   âœ… Small to medium clusters")
    print("   âœ… Simple setup requirements")
    print("   âœ… No existing Hadoop/K8s infrastructure")


if __name__ == "__main__":
    main()
