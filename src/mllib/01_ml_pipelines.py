#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
================================================================================
SPARK MLLIB #1 - Machine Learning Pipelines
================================================================================

MODULE OVERVIEW:
----------------
Spark MLlib provides scalable machine learning on distributed data.
ML Pipelines provide a high-level API for building ML workflows that include:
â€¢ Feature engineering (transformers)
â€¢ Model training (estimators)
â€¢ Model evaluation
â€¢ Hyperparameter tuning

This module demonstrates end-to-end ML pipeline construction.

PURPOSE:
--------
Learn Spark MLlib pipelines:
â€¢ Transformers (feature engineering)
â€¢ Estimators (model training)
â€¢ Pipeline construction
â€¢ Model persistence
â€¢ Production deployment patterns

ML PIPELINE ARCHITECTURE:
-------------------------
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  SPARK ML PIPELINE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. Data Ingestion                                             â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚     â”‚ Load raw data (CSV, Parquet, etc.)     â”‚                 â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                        â†“                                        â”‚
â”‚  2. Feature Engineering (Transformers)                         â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚     â”‚ â€¢ StringIndexer (categorical â†’ index)  â”‚                 â”‚
â”‚     â”‚ â€¢ OneHotEncoder (index â†’ vector)       â”‚                 â”‚
â”‚     â”‚ â€¢ VectorAssembler (combine features)   â”‚                 â”‚
â”‚     â”‚ â€¢ StandardScaler (normalization)       â”‚                 â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                        â†“                                        â”‚
â”‚  3. Model Training (Estimator)                                 â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚     â”‚ â€¢ LogisticRegression                   â”‚                 â”‚
â”‚     â”‚ â€¢ RandomForestClassifier               â”‚                 â”‚
â”‚     â”‚ â€¢ GBTClassifier                        â”‚                 â”‚
â”‚     â”‚ â€¢ LinearRegression                     â”‚                 â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                        â†“                                        â”‚
â”‚  4. Model Evaluation                                           â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚     â”‚ â€¢ Accuracy, Precision, Recall, F1      â”‚                 â”‚
â”‚     â”‚ â€¢ ROC-AUC, PR-AUC                      â”‚                 â”‚
â”‚     â”‚ â€¢ RMSE, R2 (regression)                â”‚                 â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                        â†“                                        â”‚
â”‚  5. Model Persistence                                          â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚     â”‚ â€¢ Save model to disk                   â”‚                 â”‚
â”‚     â”‚ â€¢ Load for inference                   â”‚                 â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

KEY CONCEPTS:
-------------
â€¢ Transformer: Takes DataFrame, returns transformed DataFrame
â€¢ Estimator: Takes DataFrame, returns Model (which is a Transformer)
â€¢ Pipeline: Chain of Transformers and Estimators
â€¢ Model: Trained Estimator (can transform data)
"""

from pyspark.sql import SparkSession
from pyspark.ml import Pipeline
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler
from pyspark.ml.classification import LogisticRegression, RandomForestClassifier
from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
from pyspark.sql.functions import col, when
import os


def create_spark():
    """Create Spark session for MLlib."""
    return SparkSession.builder \
        .appName("MLlib_Pipelines") \
        .master("local[*]") \
        .config("spark.sql.execution.arrow.pyspark.enabled", "true") \
        .getOrCreate()


def example1_basic_pipeline(spark):
    """
    EXAMPLE 1: Basic Classification Pipeline
    =========================================
    
    Complete ML pipeline: Features â†’ Training â†’ Evaluation
    """
    print("=" * 70)
    print("EXAMPLE 1: Basic Classification Pipeline")
    print("=" * 70)
    
    # Create sample data
    data = spark.createDataFrame([
        (0, "male", 22, 1, 0),
        (1, "female", 38, 1, 1),
        (1, "female", 26, 0, 1),
        (0, "male", 35, 1, 0),
        (1, "female", 35, 0, 1),
        (0, "male", 54, 0, 0),
        (1, "female", 27, 0, 1),
        (0, "male", 28, 1, 0),
    ] * 1000, ["survived", "sex", "age", "sibsp", "label"])
    
    print(f"\nğŸ“Š Dataset: {data.count():,} rows")
    data.show(5)
    
    # Split data
    train, test = data.randomSplit([0.8, 0.2], seed=42)
    print(f"\nâœ‚ï¸  Train: {train.count():,} | Test: {test.count():,}")
    
    # Stage 1: Index categorical features
    indexer = StringIndexer(inputCol="sex", outputCol="sex_index")
    
    # Stage 2: One-hot encode
    encoder = OneHotEncoder(inputCol="sex_index", outputCol="sex_vec")
    
    # Stage 3: Assemble features
    assembler = VectorAssembler(
        inputCols=["sex_vec", "age", "sibsp"],
        outputCol="features"
    )
    
    # Stage 4: Train model
    lr = LogisticRegression(featuresCol="features", labelCol="label")
    
    # Create pipeline
    pipeline = Pipeline(stages=[indexer, encoder, assembler, lr])
    
    print("\nğŸ”§ Pipeline stages:")
    for i, stage in enumerate(pipeline.getStages()):
        print(f"   {i+1}. {stage.__class__.__name__}")
    
    # Train
    print("\nğŸ¯ Training model...")
    model = pipeline.fit(train)
    
    # Predict
    predictions = model.transform(test)
    
    # Evaluate
    evaluator = BinaryClassificationEvaluator(labelCol="label")
    auc = evaluator.evaluate(predictions)
    
    print(f"\nğŸ“Š Model Performance:")
    print(f"   AUC-ROC: {auc:.4f}")
    
    # Show predictions
    print("\nğŸ“ Sample Predictions:")
    predictions.select("sex", "age", "label", "prediction", "probability").show(10)
    
    print("\nğŸ’¡ Pipeline Benefits:")
    print("   âœ… Reproducible workflow")
    print("   âœ… Easy to modify stages")
    print("   âœ… Single fit/transform")
    print("   âœ… Production-ready")


def example2_save_load_model(spark):
    """
    EXAMPLE 2: Model Persistence
    =============================
    
    Save and load trained models.
    """
    print("\n" + "=" * 70)
    print("EXAMPLE 2: Model Persistence")
    print("=" * 70)
    
    print("""
    ğŸ“ MODEL SAVING PATTERNS:
    
    # Save entire pipeline model
    model.write().overwrite().save("/path/to/model")
    
    # Load model
    from pyspark.ml import PipelineModel
    loaded_model = PipelineModel.load("/path/to/model")
    
    # Use for inference
    predictions = loaded_model.transform(new_data)
    
    ğŸ’¡ Best Practices:
    âœ… Version your models (v1, v2, etc.)
    âœ… Save metadata (training date, metrics)
    âœ… Test loading before deploying
    âœ… Use MLflow for experiment tracking
    
    ğŸ“‚ Directory Structure:
    models/
    â”œâ”€â”€ logistic_regression_v1/
    â”‚   â”œâ”€â”€ metadata/
    â”‚   â””â”€â”€ stages/
    â”œâ”€â”€ random_forest_v2/
    â”‚   â”œâ”€â”€ metadata/
    â”‚   â””â”€â”€ stages/
    â””â”€â”€ xgboost_v3/
        â”œâ”€â”€ metadata/
        â””â”€â”€ stages/
    
    ğŸ”„ Model Deployment Workflow:
    
    1. Train model in development
    2. Save model to staging
    3. Test model in staging
    4. Promote to production
    5. Monitor performance
    6. Rollback if needed
    """)


def example3_hyperparameter_tuning(spark):
    """
    EXAMPLE 3: Hyperparameter Tuning with Cross-Validation
    =======================================================
    
    Automated hyperparameter search.
    """
    print("\n" + "=" * 70)
    print("EXAMPLE 3: Hyperparameter Tuning")
    print("=" * 70)
    
    print("""
    ğŸ›ï¸  HYPERPARAMETER TUNING WORKFLOW:
    
    1. Define parameter grid
    2. Create cross-validator
    3. Fit on training data
    4. Get best model
    
    ğŸ“Š Example: Random Forest Tuning
    
    from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
    
    # Build pipeline
    rf = RandomForestClassifier(labelCol="label", featuresCol="features")
    pipeline = Pipeline(stages=[indexer, assembler, rf])
    
    # Parameter grid
    paramGrid = ParamGridBuilder() \\
        .addGrid(rf.numTrees, [10, 20, 50]) \\
        .addGrid(rf.maxDepth, [5, 10, 15]) \\
        .addGrid(rf.minInstancesPerNode, [1, 5, 10]) \\
        .build()
    
    # Cross-validator
    cv = CrossValidator(
        estimator=pipeline,
        estimatorParamMaps=paramGrid,
        evaluator=BinaryClassificationEvaluator(),
        numFolds=5,
        parallelism=4  # Run 4 folds in parallel
    )
    
    # Fit (this trains multiple models!)
    cvModel = cv.fit(train)
    
    # Best model
    bestModel = cvModel.bestModel
    
    # Best parameters
    print("Best Parameters:")
    for param, value in zip(paramGrid[cvModel.avgMetrics.index(max(cvModel.avgMetrics))].keys(),
                           paramGrid[cvModel.avgMetrics.index(max(cvModel.avgMetrics))].values()):
        print(f"  {param.name}: {value}")
    
    âš¡ OPTIMIZATION TIPS:
    
    âœ… Use parallelism parameter (4-8x speedup)
    âœ… Start with coarse grid, then refine
    âœ… Use stratified sampling for imbalanced data
    âœ… Cache training data for multiple iterations
    âœ… Monitor with Spark UI
    
    ğŸš€ Parallelism Example:
    
    # 3 hyperparameters Ã— 3 values each = 27 combinations
    # 5-fold CV = 135 model trainings
    # With parallelism=4: 4 models trained simultaneously
    # Time reduction: 4x faster!
    """)


def show_mllib_best_practices():
    """Best practices for MLlib pipelines."""
    print("\n" + "=" * 70)
    print("MLLIB BEST PRACTICES")
    print("=" * 70)
    
    print("""
    ğŸ¯ BEST PRACTICES:
    
    1. DATA PREPARATION
       âœ… Handle missing values
       âœ… Remove duplicates
       âœ… Balance classes (if needed)
       âœ… Feature scaling/normalization
       âŒ Don't skip EDA
    
    2. FEATURE ENGINEERING
       âœ… Domain knowledge
       âœ… Feature selection
       âœ… Handle categorical variables
       âœ… Create interaction features
       âŒ Don't overfit on training data
    
    3. MODEL TRAINING
       âœ… Use train/validation/test split
       âœ… Cross-validation for tuning
       âœ… Start with simple models
       âœ… Cache training data
       âŒ Don't train on test data
    
    4. MODEL EVALUATION
       âœ… Multiple metrics (accuracy, F1, AUC)
       âœ… Confusion matrix
       âœ… Feature importance
       âœ… Error analysis
       âŒ Don't rely on single metric
    
    5. PRODUCTION DEPLOYMENT
       âœ… Version your models
       âœ… Monitor performance
       âœ… A/B testing
       âœ… Logging and alerts
       âŒ Don't deploy without testing
    
    ğŸ“Š COMMON ALGORITHMS:
    
    Classification:
    â€¢ LogisticRegression (baseline, fast)
    â€¢ RandomForestClassifier (robust, feature importance)
    â€¢ GBTClassifier (high accuracy, slower)
    â€¢ LinearSVC (large datasets)
    â€¢ NaiveBayes (text classification)
    
    Regression:
    â€¢ LinearRegression (baseline)
    â€¢ RandomForestRegressor (robust)
    â€¢ GBTRegressor (high accuracy)
    â€¢ GeneralizedLinearRegression (various distributions)
    
    Clustering:
    â€¢ KMeans (fast, spherical clusters)
    â€¢ BisectingKMeans (hierarchical)
    â€¢ GaussianMixture (probabilistic)
    
    ğŸ’¡ ALGORITHM SELECTION:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Use Case         â”‚ Algorithm      â”‚ Why          â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Binary class     â”‚ Logistic Reg   â”‚ Baseline     â”‚
    â”‚ Multi-class      â”‚ Random Forest  â”‚ Robust       â”‚
    â”‚ Large dataset    â”‚ LinearSVC      â”‚ Scales well  â”‚
    â”‚ Imbalanced       â”‚ GBT + weights  â”‚ Handles well â”‚
    â”‚ Text             â”‚ NaiveBayes     â”‚ Fast for textâ”‚
    â”‚ Regression       â”‚ Linear Reg     â”‚ Baseline     â”‚
    â”‚ Non-linear       â”‚ Random Forest  â”‚ Captures     â”‚
    â”‚ Time series      â”‚ ARIMA/Prophet  â”‚ Specialized  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    ï¿½ï¿½ PERFORMANCE OPTIMIZATION:
    
    1. Caching:
       train.cache()  # Cache training data
       
    2. Partitioning:
       df.repartition(200)  # Optimal partitions
       
    3. Broadcast joins:
       df.join(broadcast(small_df), "key")
       
    4. Parallelism:
       CrossValidator(parallelism=8)
       
    5. Resource allocation:
       --executor-memory 16g
       --executor-cores 4
       --num-executors 10
    """)


def main():
    """Run all MLlib pipeline examples."""
    spark = create_spark()
    
    print("ğŸ¤– SPARK MLLIB - MACHINE LEARNING PIPELINES")
    print("=" * 70)
    print("\nScalable machine learning on distributed data!")
    
    # Run examples
    example1_basic_pipeline(spark)
    example2_save_load_model(spark)
    example3_hyperparameter_tuning(spark)
    
    # Show best practices
    show_mllib_best_practices()
    
    print("\n" + "=" * 70)
    print("âœ… MLLIB EXAMPLES COMPLETE")
    print("=" * 70)
    print("\nğŸ“ Key Takeaways:")
    print("   1. Pipelines = reproducible ML workflows")
    print("   2. Transformers + Estimators pattern")
    print("   3. Save/load models for production")
    print("   4. Cross-validation for tuning")
    print("   5. Monitor and version models")
    
    print("\nğŸ“š See Also:")
    print("   â€¢ 02_feature_engineering.py - Advanced features")
    print("   â€¢ 03_model_evaluation.py - Evaluation metrics")
    print("   â€¢ databricks_mlflow_example.py - MLflow tracking")
    
    spark.stop()


if __name__ == "__main__":
    main()
