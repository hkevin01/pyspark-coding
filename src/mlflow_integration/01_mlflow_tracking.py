"""
================================================================================
MLflow Model Tracking with PySpark
================================================================================

PURPOSE:
--------
Track machine learning experiments, models, and parameters using MLflow
for reproducible ML workflows and model versioning.

WHAT MLFLOW PROVIDES:
----------------------
- Experiment tracking (parameters, metrics, artifacts)
- Model registry (version control for models)
- Model serving (deploy models as REST APIs)
- Project packaging (reproducible runs)

WHY MLFLOW:
-----------
- Track 1000s of experiments systematically
- Compare model performance easily
- Reproduce results months later
- Deploy models to production
- Collaborate across team

REAL-WORLD USE CASES:
- Uber: Track 1M+ ML experiments
- Microsoft: Model versioning across teams
- Databricks: Production ML platform
- Netflix: Recommendation system deployment

KEY FEATURES:
-------------
1. TRACKING: Log parameters, metrics, models
2. PROJECTS: Package code for reproducibility
3. MODELS: Version and deploy models
4. REGISTRY: Manage model lifecycle

================================================================================
"""

from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.regression import LinearRegression
# import mlflow  # Requires mlflow package

def create_spark():
    """Create Spark session for MLflow integration."""
    return SparkSession.builder \
        .appName("MLflow_Tracking") \
        .getOrCreate()

def example_1_track_experiment(spark):
    """
    Example 1: Track ML experiment with MLflow.
    
    TRACKS:
    - Model hyperparameters
    - Training metrics (RMSE, R2)
    - Model artifacts
    - Training dataset info
    """
    print("\n" + "=" * 80)
    print("EXAMPLE 1: MLFLOW EXPERIMENT TRACKING")
    print("=" * 80)
    
    # Sample training data
    data = spark.createDataFrame([
        (1.0, 2.0, 3.0),
        (2.0, 3.0, 5.0),
        (3.0, 4.0, 7.0),
    ], ["feature1", "feature2", "label"])
    
    # Prepare features
    assembler = VectorAssembler(
        inputCols=["feature1", "feature2"],
        outputCol="features"
    )
    training_data = assembler.transform(data)
    
    # Train model
    lr = LinearRegression(featuresCol="features", labelCol="label")
    model = lr.fit(training_data)
    
    print(f"\nðŸ“Š Model trained!")
    print(f"   Coefficients: {model.coefficients}")
    print(f"   Intercept: {model.intercept}")
    
    # MLflow would track:
    print("\nðŸ’¾ MLflow would track:")
    print("   â€¢ Parameters: maxIter, regParam")
    print("   â€¢ Metrics: RMSE, R2, MAE")
    print("   â€¢ Model: Serialized model file")
    print("   â€¢ Tags: experiment_name, user, git_commit")
    
    return model

def main():
    """Main execution."""
    print("\n" + "ðŸ“Š" * 40)
    print("MLFLOW MODEL TRACKING")
    print("ðŸ“Š" * 40)
    
    spark = create_spark()
    example_1_track_experiment(spark)
    
    print("\nâœ… MLflow tracking examples complete!")
    spark.stop()

if __name__ == "__main__":
    main()
