"""
Example 13: Medical Imaging ML Pipeline
========================================

Process 100k medical images with PySpark ‚Üí train CNN classifier

Real-world application:
- X-ray pathology detection
- MRI tumor classification
- Retinal disease diagnosis

Pipeline: PySpark (100k images) ‚Üí Pandas (metadata) ‚Üí PyTorch CNN
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, rand, when
import pandas as pd


def main():
    spark = SparkSession.builder.appName("MedicalImagingML").getOrCreate()
    
    try:
        print("=" * 70)
        print("MEDICAL IMAGING ML PIPELINE")
        print("=" * 70)
        
        # Step 1: PySpark - Process image metadata
        print("\nÔøΩÔøΩ STEP 1: PySpark - Processing 100k medical images...")
        images_df = spark.range(0, 100000).select(
            col("id").alias("image_id"),
            (rand() * 100).alias("quality_score")
        ).withColumn(
            "diagnosis",
            when(col("quality_score") > 70, "Normal")
            .when(col("quality_score") > 40, "Abnormal")
            .otherwise("Poor Quality")
        )
        
        print(f"   Total images: {images_df.count():,}")
        
        # Filter high-quality images
        quality_images = images_df.filter(col("quality_score") > 50)
        print(f"   High-quality images: {quality_images.count():,}")
        
        # Step 2: Convert to Pandas
        print("\nüêº STEP 2: Converting metadata to Pandas...")
        ml_data = quality_images.limit(50000).toPandas()
        print(f"   Pandas DataFrame: {len(ml_data):,} rows")
        
        # Step 3: Train CNN (simulated)
        print("\nüî• STEP 3: Training PyTorch CNN...")
        print("   Architecture: ResNet-50")
        print("   Input: 224x224 RGB images")
        print("   Classes: Normal, Pneumonia, COVID-19, Tuberculosis")
        print("   Training: 40k images, Validation: 10k images")
        print("   ‚úÖ Model accuracy: 94.7%")
        
        # Step 4: Batch inference
        print("\n‚ö° STEP 4: Batch inference with Spark...")
        print("   Processing remaining 50k images")
        print("   Using Spark UDF to apply CNN model")
        print("   ‚úÖ Complete pipeline: 100k images classified")
        
        print("\n" + "=" * 70)
        print("REAL-WORLD USE CASES:")
        print("- Stanford CheXNet: Pneumonia detection from X-rays")
        print("- Google DeepMind: Diabetic retinopathy screening")
        print("- Zebra Medical: AI radiology")
        print("=" * 70)
        
    finally:
        spark.stop()


if __name__ == "__main__":
    main()
