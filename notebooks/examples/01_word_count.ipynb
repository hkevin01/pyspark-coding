{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Word Count\n",
    "\n",
    "The classic MapReduce example - counting words in text data.\n",
    "\n",
    "This demonstrates:\n",
    "- Working with text data\n",
    "- String operations\n",
    "- Grouping and aggregation\n",
    "- Sorting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"WordCount\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text data\n",
    "text_data = [\n",
    "    (\"PySpark is great for big data processing\",),\n",
    "    (\"Big data requires distributed computing\",),\n",
    "    (\"PySpark makes big data processing easy\",),\n",
    "    (\"Spark is fast and powerful\",),\n",
    "    (\"Data processing with PySpark is fun\",)\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(text_data, [\"text\"])\n",
    "print(\"Original text:\")\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into words\n",
    "words_df = df.select(F.explode(F.split(F.lower(F.col(\"text\")), \" \")).alias(\"word\"))\n",
    "\n",
    "print(\"\\nIndividual words:\")\n",
    "words_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count word occurrences\n",
    "word_counts = words_df.groupBy(\"word\").count()\n",
    "\n",
    "print(\"\\nWord counts (unsorted):\")\n",
    "word_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by count (descending)\n",
    "word_counts_sorted = word_counts.orderBy(F.col(\"count\").desc())\n",
    "\n",
    "print(\"\\nTop 10 most frequent words:\")\n",
    "word_counts_sorted.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out common words and show results\n",
    "stop_words = [\"is\", \"for\", \"and\", \"with\", \"the\", \"a\", \"an\"]\n",
    "\n",
    "filtered_counts = word_counts_sorted.filter(~F.col(\"word\").isin(stop_words))\n",
    "\n",
    "print(\"\\nWord counts (excluding stop words):\")\n",
    "filtered_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "total_words = words_df.count()\n",
    "unique_words = word_counts.count()\n",
    "\n",
    "print(f\"\\nTotal words: {total_words}\")\n",
    "print(f\"Unique words: {unique_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
